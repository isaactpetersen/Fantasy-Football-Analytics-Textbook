# Causal Inference {#sec-causalInference}

## Getting Started {#sec-causalInferenceGettingStarted}

### Load Packages {#sec-causalInferenceLoadPackages}

```{r}
library("dagitty")
```

## Correlation Does Not Imply Causality {#sec-correlationCausality}

As described in @sec-correlationCausation, there are several reasons why two variables, $X$ and $Y$, might be correlated:

- $X$ causes $Y$
- $Y$ causes $X$
- a third variable (i.e., confound), $Z$, influences both $X$ and $Y$
- the association between $X$ and $Y$ is spurious

## Criteria for Causality {#sec-conditionsForCausality}

How do we know whether two processes are causally related?
There are three criteria for establishing causality [@Shadish2002]:

1. The cause (e.g., the independent or predictor variable) temporally precedes the effect (i.e., the dependent or outcome variable).
1. The cause is related to (i.e., associated with) the effect.
1. There are no other alternative explanations for the effect apart from the cause.

The first criterion for establishing causality involves temporal precedence.
In order for a cause to influence an effect, the cause must occur before the effect.
For instance, if sports drink consumption influences player performance, the sports drink consumption (that is presumed to influence performance) must occur prior to the performance improvement.
Establishing the first criterion eliminates the possibility that the association between the purported cause and effect reflects reverse causation.
Reverse causation occurs when the purported effect is actually the cause of the purported cause, rather than the other way around.
For instance, if sports drink consumption occurs only once, and it occurs only before and not after performance, then we have ruled out the possibility of reverse causation (i.e., that better performance causes players to consume sports drink).

The second criterion involves association.
The purported cause must be associated with the purported effect.
Nevertheless, as the maxim goes, "correlation does not imply causality."
Just because two variables are correlated does not necessarily mean that they are causally related.
However, correlation is useful because causality requires that the two processes be correlated.
That is, correlation is a necessary but insufficient condition for causality.
For instance, if sports drink consumption influences player performance, sports drink consumption must be associated with performance improvement.

The third criterion involves ruling out alternative reasons why the purported cause and effect may be related.
As noted in @sec-correlationCausality, there are four reasons why $X$ may be correlated with $Y$.
If we meet the first criterion of causality, we have removed the possibility that $Y$ causes $X$ (i.e., reverse causality).
To meet the third criterion of causality, we need to remove the possibility that the association reflects a third variable (confound) that influences both the cause and effect, and we need to remove the possibility that the association is spurious—the possibility that the association between the purported cause and effect is due to random chance.
There are multiple approaches to meeting the third criterion of causality, such as by use of [experiments](#sec-causalInferenceExperiment), [longitudinal designs](#sec-causalInferenceLongitudinal), [control variables](#sec-causalInferenceControlVariables), [within-subject designs](#sec-causalInferenceWithinSubject), and [genetically informed designs](#sec-causalInferenceGeneticallyInformed), as described in @sec-approachesCausalInference.

## Causal Diagrams {#sec-causalDiagrams}

A key tool when describing a research question or hypothesis is to create a conceptual depiction of the hypothesized causal processes.
A causal diagram depicts the hypothesized causal processes that link two or more variables.
A common form of causal diagrams is the directed acyclic graph (DAG).
DAGs provide a helpful tool to communicate about causal questions and help identify how to avoid bias (i.e., over-estimation) in associations between variables due to confounding (i.e., common causes) [@Digitale2022].
You can use the `R` package `dagitty` [@Textor2017] or the associated browser-based extension, DAGitty: https://dagitty.net (archived at https://perma.cc/U9BY-VZE2) to create DAGs.
Examples of various causal diagrams that could explain why *X* is associated with *Y* are in @fig-XCausesY, @fig-YCausesX, and @fig-YCausesX.

```{r}
#| label: fig-XCausesY
#| fig-cap: "Causal Diagram (Directed Acyclic Graph) Depicting *X* Causing *Y*."

XCausesY <- dagitty::dagitty("dag{
  X -> Y
}")

plot(dagitty::graphLayout(XCausesY))
```

```{r}
#| label: fig-YCausesX
#| fig-cap: "Causal Diagram (Directed Acyclic Graph) Depicting Reverse Causation: *Y* Causing *X*."

YCausesX <- dagitty::dagitty("dag{
  Y -> X
}")

plot(dagitty::graphLayout(YCausesX))

ZCausesXandY <- dagitty::dagitty("dag{
  Z -> Y
  Z -> X
  X <-> Y
}")

plot(dagitty::graphLayout(ZCausesXandY))
```

```{r}
#| label: fig-YCausesX
#| fig-cap: "Causal Diagram (Directed Acyclic Graph) Depicting a Third Variable Confound, *Z*, Causing *X* and *Y*, Thus Explaining Why *X* and *Y* are associated."

ZCausesXandY <- dagitty::dagitty("dag{
  Z -> Y
  Z -> X
  X <-> Y
}")

plot(dagitty::graphLayout(ZCausesXandY))
```

## Approaches for Causal Inference {#sec-approachesCausalInference}

### Experimental Designs {#sec-causalInferenceExperiment}

As described in @sec-experiment, [experimental designs](#sec-experiment) are designs in which participants are randomly assigned to one or more levels of the [independent variable](#sec-experiment) to observe its effects on the [dependent variable](#sec-experiment).
[Experimental designs](#sec-experiment) provide the strongest tests of causality because they can rule out reverse causation and third variables.
For instance, by manipulating sports drink consumption before the player performs, they can eliminate the possibility that reverse causation explains the effect of the [independent variable](#sec-experiment) on the [dependent variable](#sec-experiment).
Second, through randomly assigning players to consume or not consume sports drink, this holds everything else constant (so long as the groups are evenly distributed according to other factors, such as their age, weight, etc.) and thus removes the possibility that third variable confounds explain the effect of the [independent variable](#sec-experiment) on the [dependent variable](#sec-experiment).

### Quasi-Experimental Designs {#sec-causalInferenceQuasiExperiment}

Although [experimental designs](#sec-causalInferenceExperiment) provide the strongest tests of causality, manytimes they are impossible, unethical, or impractical to conduct.
For instance, it would likely not be practical to randomly assign National Football League (NFL) players to either consume or not consume sports drink before their games.
Players have their pregame rituals and routines and many would likely not agree to participate in such a study.
Thus, we often rely on quasi-experimental designs such as natural experiments and [observational/correlational designs](#sec-correlationalStudy).

#### Longitudinal Designs {#sec-causalInferenceLongitudinal}

Research designs can be compared in terms of their [internal validity](#sec-internalValidity)—the extent to which we can be confident about causal inferences.
A cross-sectional association is depicted in @fig-crossSectional:

::: {#fig-crossSectional}
![](images/Longitudinal-01.png)

Cross-Sectional Association. T1 = Timepoint 1. From @Petersen2024a and @PetersenPrinciplesPsychAssessment.
:::

For instance, we might observe that sports drink consumptions is concurrently associated with better player performance.
Among [observational/correlational research designs](#sec-correlationalStudy), [cross-sectional designs](#sec-crossSectional) tend to have the weakest [internal validity](#sec-internalValidity).
For the reasons described in @sec-correlationCausality, if we observe a cross-sectional association between $X$ (e.g., sports drink consumption) and $Y$ (e.g., player performance), we have little confidence that $X$ causes $Y$.
As a result, [longitudinal designs](#sec-longitudinal) can be valuable for more closely approximating causality if an [experimental designs](#sec-causalInferenceExperiment) is not possible.
Consider a lagged association that might be observed in a [longitudinal design](#sec-longitudinal), as in @fig-laggedAssociation, which is a slightly better approach than relying on cross-sectional associations:

::: {#fig-laggedAssociation}
![](images/Longitudinal-02.png)

Lagged Association. T1 = Timepoint 1. T2 = Timepoint 2. From @Petersen2024a and @PetersenPrinciplesPsychAssessment.
:::

For instance, we might observe that sports drink performance *before* the game is associated with better player performance *during* the game.
A lagged association has somewhat better [internal validity](#sec-internalValidity) than a cross-sectional association because we have greater evidence of temporal precedence—that the influence of the predictor *precedes* the outcome because the predictor was assessed before the outcome and it shows a predictive association.
However, part of the association between the predictor with later levels of the outcome could be due to prior levels of the outcome that are stable across time.
That is, it could be that better player performance leads players to consume more sports drink and that player performance is relatively stable across time.
In such a case, it may be observed that sports drink consumption predicts later player performance even though player performance influences sports drink consumption, rather than the other way around
Thus, consider an even stronger alternative—a lagged association that controls for prior levels of the outcome, as in @fig-laggedAssociationControlPriorLevels:

::: {#fig-laggedAssociationControlPriorLevels}
![](images/Longitudinal-03.png)

Lagged Association, Controlling for Prior Levels of the Outcome. T1 = Timepoint 1. T2 = Timepoint 2. From @Petersen2024a and @PetersenPrinciplesPsychAssessment.
:::

For instance, we might observe that sports drink performance *before* the game is associated with better player performance *during* the game, while controlling for prior player performance.
A lagged association controlling for prior levels of the outcome has better [internal validity](#sec-internalValidity) than a lagged association that does not control for prior levels of the outcome.
A lagged association that controls for prior levels further reduces the likelihood that the association owes to the reverse direction of effect, because earlier levels of the outcome are controlled.
However, consider an even stronger alternative—lagged associations that control for prior levels of the outcome and that simultaneously test each direction of effect, as depicted in @fig-crossLaggedPanelModel:

::: {#fig-crossLaggedPanelModel}
![](images/Longitudinal-04.png)

Lagged Association, Controlling for Prior Levels of the Outcome, Simultaneously Testing Both Directions Of Effect. T1 = Timepoint 1. T2 = Timepoint 2. From @Petersen2024a and @PetersenPrinciplesPsychAssessment.
:::

Lagged associations that control for prior levels of the outcome and that simultaneously test each direction of effect provide the strongest [internal validity](#sec-internalValidity) among [observational/correlational designs](#sec-correlationalStudy).
Such a design can help better clarify which among the variables is the chicken and the egg—which variable is more likely to be the cause and which is more likely to be the effect.
If there are bidirectional effects, such a design can also help clarify the magnitude of each direction of effect.
For instance, we can simultaneously evaluate the extent to which sports drink predicts later player performance (while controlling for prior performance) and the reverse—player performance predicting later sports drink consumption (while contorlling for prior sports drink consumption).

#### Within-Subject Analyses {#sec-causalInferenceWithinSubject}

Another design feature of [longitudinal designs](#sec-causalInferenceLongitudinal) that can lead to greater [internal validity](#sec-internalValidity) is the use of within-subject analyses.
Between-subject analyses, might examine, for instanc, whether players who consume more sports drink perform better on average compared to players who consume less sports drink.
However, there are other between-person differences that could explain any observed between-subject associations between sports drink consumption and players performance.
Another approach could be to apply within-subject analyses.
For instance, you could examining whether, within the same individual, if a player consumes a sports drink, do they perform better compared to games in which they did not consume a sports drink.
When we control for prior levels of the outcome in the prediction, we are evaluating whether the predictor is associated with *change* in the outcome.
Predicting change provides stronger evidence consistent with causality because it uses the individual as their own control and controls for many time-invariant confounds (i.e., confounds that do not change across time).

#### Control Variables {#sec-causalInferenceControlVariables} 

One of the plausible alternatives to the inference that $X$ causes $Y$ is that there are third variable confounds that influence both $X$ and $Y$, thus explaining why $X$ and $Y$ are associated, as depicted in @fig-correlationAndCausation3 and @fig-YCausesX.
Thus, another approach that can help increase [internal validity](#sec-internalValidity) is to include plausible confounds as control variables.
For instance, if a third variable such as education level might be a confound that influences both sports drink consumption and player performance, you could include education level as a [covariate](#sec-covariates) in the model.
Inclusion of a [covariate](#sec-covariates) attempts to control for the variable by examining the association between the [predictor variable](#sec-correlationalStudy) and the [outcome variable](#sec-correlationalStudy) while holding the [covariate](#sec-covariates) variables constant.
For instance, such a model would examine whether, when accounting for education level, there is an association between sports drink consumption and player performance.

Failure to control for important third variables can lead to erroneous conclusions, as evidenced by the association depicted in @fig-simpsonParadox.
In the example, if we did not control for gender, we would infer that there is a positive association between dosage and recovery probability.
However, when we examine each men and women separately, we learn that the association between dosage and recovery probability is actually negative within each gender group.
Thus, in this case, failure to control for gender would lead to false inferences about the association between dosage and recovery probability.

::: {#fig-simpsonParadox}
![](images/simpsonParadox.png)

Example Where Failing to Control for a Variable (In This Case, Gender) Would Lead to False Inferences. In this example, the association between dosage and recovery probability is positive at the population level, but the association is negative among men and women separately. (Figure reprinted from @Kievit2013, Figure 1, p. 2. Kievit, R., Frankenhuis, W., Waldorp, L., & Borsboom, D. (2013). Simpson's paradox in psychological science: a practical guide. *Frontiers in Psychology*, *4*(513). [https://doi.org/10.3389/fpsyg.2013.00513](https://doi.org/10.3389/fpsyg.2013.00513))
:::

#### Genetically Informed Designs {#sec-causalInferenceGeneticallyInformed}

::: {.content-visible when-format="html"}

## Session Info {#sec-causalInferenceSessionInfo}

```{r}
sessionInfo()
```

:::
