{{< include _chunk-timing.qmd >}}

# Multiple Regression {#sec-multipleRegression}

This chapter provides an overview of multiple regression.

## Getting Started {#sec-multipleRegressionGettingStarted}

### Load Packages {#sec-multipleRegressionLoadPackages}

```{r}
library("petersenlab")
library("rms")
library("car")
library("caret")
library("lme4")
library("performance")
library("lavaan")
library("mice")
library("miceadds")
library("interactions")
library("brms")
library("parallelly")
library("robustbase")
library("ordinal")
library("MASS")
library("broom")
library("effectsize")
library("tidymodels")
library("tidyverse")
library("knitr")
```

### Load Data {#sec-multipleRegressionLoadData}

```{r}
#| eval: false
#| include: false

load(file = file.path(path, "/OneDrive - University of Iowa/Teaching/Courses/Fantasy Football/Data/player_stats_weekly.RData", fsep = ""))
load(file = file.path(path, "/OneDrive - University of Iowa/Teaching/Courses/Fantasy Football/Data/player_stats_seasonal.RData", fsep = ""))
```

```{r}
load(file = "./data/player_stats_weekly.RData")
load(file = "./data/player_stats_seasonal.RData")
```

We created the `player_stats_weekly.RData` and `player_stats_seasonal.RData` objects in @sec-calculatePlayerAge.

## Overview of Multiple Regression {#sec-multipleRegressionOverview}

Multiple regression is an extension of [correlation](#sec-correlation).
[Correlation](#sec-correlation) examines the association between one [predictor variables](#sec-correlationalStudy) and one [outcome variable](#sec-correlationalStudy).
Multiple regression examines the association between *multiple* [predictor variables](#sec-correlationalStudy) and one [outcome variable](#sec-correlationalStudy).
It allows obtaining a more accurate estimate of the unique contribution of a given [predictor variable](#sec-correlationalStudy), by controlling for other variables ([covariates](#sec-covariates)).

Regression with one [predictor variable](#sec-correlationalStudy) takes the form of @eq-regression:

$$
y = \beta_0 + \beta_1x_1 + \epsilon
$$ {#eq-regression}

where $y$ is the [outcome variable](#sec-correlationalStudy), $\beta_0$ is the intercept, $\beta_1$ is the slope, $x_1$ is the [predictor variable](#sec-correlationalStudy), and $\epsilon$ is the error term.

A regression line is depicted in @fig-regression.

```{r}
#| include: false
#| eval: false

set.seed(52242)
regression <- data.frame(outcome = rnorm(40, mean = 5, sd = 2))

regression$predictor <- complement(regression$outcome, .5)
regression$predictor <- regression$predictor + abs(min(regression$predictor))

lm(
  outcome ~ predictor,
  data = regression)

ggplot2::ggplot(
  data = regression,
  aes(
    x = predictor,
    y = outcome,
  )
) +
  geom_point() +
  geom_smooth(
    method = "lm",
    linewidth = 2,
    se = FALSE,
    fullrange = TRUE) +
  scale_x_continuous(
    lim = c(0,8),
    breaks = seq(from = 0, to = 8, by = 2),
    expand = c(0,0)
  ) +
  scale_y_continuous(
    lim = c(0,8),
    breaks = seq(from = 0, to = 8, by = 2),
    expand = c(0,0)
  ) +
  labs(
    x = "Predictor Variable",
    y = "Outcome Variable",
    title = "Regression Best-Fit Line"
  ) +
  theme_classic(
    base_size = 16) +
  theme(legend.title = element_blank())

ggsave("./images/regression.pdf", width = 6, height = 6)
```

::: {#fig-regression}
![](images/regression.png){fig-alt="A Regression Best-Fit Line."}

A Regression Best-Fit Line.
:::

Regression with multiple [predictors](#sec-correlationalStudy)—i.e., multiple regression—takes the form of @eq-multipleRegression:

$$
y = \beta_0 + \beta_1x_1 + \beta_2x_2 + ... + \beta_px_p + \epsilon
$$ {#eq-multipleRegression}

where $p$ is the number of [predictor variables](#sec-correlationalStudy).
Multiple regression is basically a weighted sum of the [predictor variables](#sec-correlationalStudy), and adding an intercept.
Under the hood, multiple regression seeks to identify the best weight for each [predictor](#sec-correlationalStudy).
The intercept is the expected value of the outcome variable when all of the predictor variables have a value of zero.

## Components {#sec-multipleRegressionComponents}

- $B$ = unstandardized coefficient: direction and magnitude of the estimate (original scale)
- $\beta$ (beta) = standardized coefficient: direction and magnitude of the estimate (standard deviation scale)
- $SE$ = standard error: uncertainty of unstandardized estimate

The unstandardized regression coefficient ($B$) is interpreted such that, for every unit change in the [predictor variable](#sec-correlationalStudy), there is a __ unit change in the [outcome variable](#sec-correlationalStudy).
For instance, when examining the association between age and fantasy points, if the unstandardized regression coefficient is 2.3, players score on average 2.3 more points for each additional year of age.
(In reality, we might expect a nonlinear, inverted-U-shaped association between age and fantasy points such that players tend to reach their peak in the middle of their careers.)
Unstandardized regression coefficients are tied to the metric of the raw data.
Thus, a large unstandardized regression coefficient for two variables may mean completely different things.
Holding the strength of the association constant, you tend to see larger unstandardized regression coefficients for variables with smaller units and smaller unstandardized regression coefficients for variables with larger units.

Standardized regression coefficients can be obtained by standardizing the variables to [*z*-scores](#sec-zScores) so they all have a mean of zero and standard deviation of one.
The standardized regression coefficient ($\beta$) is interpreted such that, for every standard deviation change in the [predictor variable](#sec-correlationalStudy), there is a __ standard deviation change in the [outcome variable](#sec-correlationalStudy).
For instance, when examining the association between age and fantasy points, if the standardized regression coefficient is 0.1, players score on average 0.1 standard deviation more points for each additional standard deviation of their year of age.
Standardized regression coefficients—though not the case in all instances—tend to fall between [−1, 1].
Thus, standardized regression coefficients tend to be more comparable across variables and models compared to unstandardized regression coefficients.
In this way, standardized regression coefficients provide a meaningful index of [effect size](#sec-practicalSignificance).

The *standard error* of a regression coefficient represents the imprecision or uncertainty of the parameter.
If we have less uncertainty (i.e., more confidence) about the parameter, the standard error will be small, reflecting greater precision of the regression coefficient.
If we have more uncertainty (i.e., less confidence) about the parameter, the standard error will be large, reflecting less precision of the regression coefficient.
If we used the same sampling procedure repeatedly and calculated the regression coefficient each time, the true parameter in the population would fall 68% of the time within the interval of:  $[\text{model parameter estimate for the regression coefficient} \pm 1 \text{ standard error}]$.
The standard error is related to the sample size—the larger the sample size, the smaller the standard error (the greater the precision of our estimate of the regression coefficient).
Otherwise said, having more data gives more precise estimates and thus increases [statistical power](#sec-statisticalPower).

A *confidence interval* represents a range of plausible values such that, with repeated sampling, the true value falls within a given interval with some confidence.
Our parameter estimate for the regression coefficient, plus or minus 1 standard error, reflects the 68% confidence interval for the coefficient.
The 95% confidence interval is computed as the parameter estimated plus or minus 1.96 standard errors.
For instance, if the parameter estimate for the regression coefficient is 0.50, and the standard error is 0.10, the 95% confidence interval is [0.30, 0.70]: $0.5 - (1.96 \times 0.10) = 0.3$; $0.5 + (1.96 \times 0.10) = 0.7$.
That is, if we used the same sampling procedure repeatedly, the true value of the regression coefficient would be expected to be 95% of the time somewhere between 0.30 to 0.70.

## Types of Regression {#sec-multipleRegressionTypes}

When the outcome variable is continuous, [linear regression](#sec-multipleRegressionLinear) is common.
However, there are other types of regression depending on type and distribution of the [outcome variable](#sec-correlationalStudy).
For instance, if the [outcome variable](#sec-correlationalStudy) is binary, [logistic regression](#sec-multipleRegressionLogistic) would be used.
If the [outcome variable](#sec-correlationalStudy) is an ordered categorical variable, [ordinal regression](#sec-multipleRegressionOrdinal) would be used.
If the [outcome variable](#sec-correlationalStudy) is a count, [Poisson](#sec-multipleRegressionPoisson) or [negative binomial](#sec-multipleRegressionNegativeBinomial) regression would be preferable.
If the [outcome variable](#sec-correlationalStudy) is a proportion, [beta regression](#sec-multipleRegressionBeta) would be used.

Here are examples of each:

### Linear Regression {#sec-multipleRegressionLinear}

We fit a linear regression model using the `lm()` function.

```{r}
#| label: linear-regression

linearRegression <- lm(
  fantasyPoints ~ age + height + weight + target_share,
  data = player_stats_seasonal %>% filter(position %in% c("WR")),
  na.action = "na.exclude"
)

summary(linearRegression)

print(effectsize::standardize_parameters(linearRegression, method = "refit"), digits = 2)
```

### Logistic Regression {#sec-multipleRegressionLogistic}

We fit a logistic regression model using the `glm()` function and specifying `family = binomial()`.
To calculate the model $R^2$, we use the `r2()` function of the `performance` package [@R-performance; @Ludecke2021_packages].

```{r}
#| label: logistic-regression

newdata <- player_stats_weekly %>%
  mutate( # create a binary variable to be used as the outcome variable
    receiving_td = case_when(
      is.na(receiving_tds) ~ NA_real_, # keep NA
      receiving_tds >= 1   ~ 1,
      receiving_tds == 0   ~ 0
    )
  )

logisticRegression <- glm(
  receiving_td ~ age + height + weight + target_share,
  data = newdata %>% filter(position %in% c("WR")),
  family = binomial(),
  na.action = "na.exclude"
)

summary(logisticRegression)
performance::r2(logisticRegression)
print(effectsize::standardize_parameters(logisticRegression, method = "refit"), digits = 2)

broom::tidy(
  logisticRegression,
  exponentiate = TRUE,
  conf.int = TRUE)
```

### Ordinal Regression {#sec-multipleRegressionOrdinal}

We fit an ordinal regression model using the `clm()` function of the `ordinal` package [@R-ordinal].

```{r}
#| label: ordinal-regression

newdata <- player_stats_weekly
newdata$receiving_tdsFactor <- factor(newdata$receiving_tds, ordered = TRUE)
table(newdata$receiving_tdsFactor)

ordinalRegression <- ordinal::clm(
  receiving_tdsFactor ~ age + height + target_share,
  data = newdata %>% filter(position %in% c("WR")),
  na.action = "na.exclude"
)

summary(ordinalRegression)
performance::r2(ordinalRegression)
print(effectsize::standardize_parameters(ordinalRegression, method = "refit"), digits = 2)

broom::tidy(
  ordinalRegression,
  exponentiate = TRUE,
  conf.int = TRUE)
```

### Poisson Regression {#sec-multipleRegressionPoisson}

We fit a Poisson regression model using the `glm()` function and specifying `family = poisson()`.

```{r}
#| label: poisson-regression

poissonRegression <- glm(
  receiving_tds ~ age + height + weight + target_share,
  data = newdata %>% filter(position %in% c("WR")),
  family = poisson(),
  na.action = na.exclude
)

summary(poissonRegression)
performance::r2(poissonRegression)
print(effectsize::standardize_parameters(poissonRegression, method = "refit"), digits = 2)

broom::tidy(
  poissonRegression,
  exponentiate = TRUE,
  conf.int = TRUE)
```

### Negative Binomial Regression {#sec-multipleRegressionNegativeBinomial}

We fit a negative binomial regression model using the `glm.nb()` function of the `MASS` package [@R-MASS].

```{r}
#| label: negative-binomial-regression

negativeBinomialRegression <- MASS::glm.nb(
  receiving_tds ~ age + height + weight + target_share,
  data = newdata %>% filter(position %in% c("WR")),
  na.action = na.exclude,
  control = glm.control(maxit = 10000)
)

summary(negativeBinomialRegression)
performance::r2(negativeBinomialRegression)
print(effectsize::standardize_parameters(negativeBinomialRegression, method = "refit"), digits = 2)

broom::tidy(
  negativeBinomialRegression,
  exponentiate = TRUE,
  conf.int = TRUE)
```

### Beta Regression {#sec-multipleRegressionBeta}

We fit a (Bayesian) zero-one-inflated beta regression model (to allow for zeros and ones) using the `brm()` function of the `brms` package [@R-brms] and specifying `family = zero_one_inflated_beta()`.

::: {#nte-bayesianBetaRegression .callout-note title="Bayesian beta regression"}
Note: the following code that runs the model takes a while.
If you just want to save time and load the model object instead of running the model, you can load the model object (which has already been fit) using this code:

```{r}
load(url("https://osf.io/download/fe37j/"))
```
:::

```{r}
#| label: beta-regression
#| output: false
#| eval: false

betaRegression <- brms::brm(
  formula = target_share ~ age + height + weight,
  data = newdata %>% filter(position %in% c("WR")),
  family = zero_one_inflated_beta(),
  cores = 4,
  threads = threading(parallelly::availableCores()),
  seed = 52242,
  silent = 0
)
```

```{r}
#| eval: false
#| include: false

save(
  betaRegression,
  file = "./data/betaRegression.RData")
```

```{r}
#| eval: false
#| include: false

load(file = file.path(path, "/OneDrive - University of Iowa/Teaching/Courses/Fantasy Football/Data/betaRegression.RData", fsep = ""))
```

```{r}
#| include: false

load(url("https://osf.io/download/fe37j/"))
```

```{r}
#| label: beta-regression-summmary

summary(betaRegression)
performance::r2(betaRegression)
```

## Assumptions of Multiple Regression {#sec-assumptionsRegression}

Linear regression models make the following assumptions:

- there is a linear association between the [predictor variable](#sec-correlationalStudy) and the [outcome variable](#sec-correlationalStudy)
- there is homoscedasticity of the residuals; the residuals do not differ as a function of the [predictor variable](#sec-correlationalStudy) or as a function of the [outcome variable](#sec-correlationalStudy)
- the residuals are independent; they are uncorrelated with each other
- the residuals are normally distributed

Homoscedasticity of the residuals means that the variance of the residuals does not differ as a function of the [outcome variable](#sec-correlationalStudy) or as a function of the [predictor variable](#sec-correlationalStudy) (i.e., the residuals show constant variance as a function of [outcome](#sec-correlationalStudy)/[predictors](#sec-correlationalStudy)).
If the residuals differ as a function of the [outcome](#sec-correlationalStudy) or [predictor](#sec-correlationalStudy) variable, this is called heterotoscedasticity.

Those are some of the key assumptions of multiple regression.
However, there are additional assumptions of multiple regression, including ones discussed in the chapter on [Causal Inference](#sec-causalInference).
For instance, the variables included should reflect a causal process such that the [predictor variables](#sec-correlationalStudy) influence the [outcome variable](#sec-correlationalStudy), and not the other way around.
That is, the [outcome variable](#sec-correlationalStudy) should not influence the [predictor variables](#sec-correlationalStudy) (i.e., there should be no reverse causation).
In addition, it is important control for any [confound(s)](#sec-causalDiagramConfounding).
If a [confound](#sec-causalDiagramConfounding) is not controlled for, this is called *omitted-variable bias*, and it leads the researcher to incorrectly attribute the effects of the omitted variable to the included variables.

### Evaluating and Addressing Assumptions of Multiple Regression {#sec-assumptionsRegressionEvaluating}

#### Linear Association {#sec-assumptionsRegressionEvaluatingLinearAssociation}

To evaluate the shape of the association between the [predictor variables](#sec-correlationalStudy) and the [outcome variable](#sec-correlationalStudy), we can examine [scatterplots](#sec-scatterplot) (@fig-linearNonlinearAssociations), residual plots (@fig-residualPlots), marginal model plots (@fig-marginalModelPlots), added-variable plots (@fig-addedVariablePlots), and component-plus-residual plots (@fig-componentPlusResidualPlots).
Residual plots depict the residuals (errors) on the y-axis as a function of the fitted values or a specific [predictor](#sec-correlationalStudy) on the x-axis.
Marginal model plots are basically glorified [scatterplots](#sec-scatterplot) that depict the [outcome variable](#sec-correlationalStudy) (both in terms of observed values and model-fitted values) on the y-axis and the [predictor variables](#sec-correlationalStudy) on the x-axis.
Added-variable plots depict the *unique* association of each [predictor variables](#sec-correlationalStudy) with the [outcome variable](#sec-correlationalStudy) when controlling for all the other [predictor variables](#sec-correlationalStudy) in the model.
Component-plus-residual plots depict partial residuals on the y-axis as a function of each [predictor variable](#sec-correlationalStudy) on the x-axis, where a partial residual for a given [predictor](#sec-correlationalStudy) is the effect of a given predictor (thus controlling for all the other [predictor variables](#sec-correlationalStudy) in the model) plus the residual from the full model.

Examples of linear and nonlinear associations are depicted with [scatterplots](#sec-scatterplot) in @fig-linearNonlinearAssociations.

```{r}
#| layout-ncol: 2
#| label: fig-linearNonlinearAssociations
#| fig-cap: "Example Associations Depicted With Scatterplots."
#| fig-alt: "Example Associations Depicted With Scatterplots."
#| fig-subcap:
#|   - "Example of a Linear Association"
#|   - "Example of a Nonlinear Association"
#| code-fold: true

set.seed(52242)

sampleSize <- 1000
quadraticX <- runif(
  sampleSize,
  min = -4,
  max = 4)
linearY <- quadraticX + rnorm(sampleSize, mean = 0, sd = 0.5)
quadraticY <- quadraticX ^ 2 + rnorm(sampleSize)
quadraticData <- cbind(quadraticX, quadraticY) %>%
  data.frame %>%
  arrange(quadraticX)

quadraticModel <- lm(
  quadraticY ~ quadraticX + I(quadraticX ^ 2),
  data = quadraticData)

quadraticNewData <- data.frame(
  quadraticX = seq(
    from = min(quadraticData$quadraticX),
    to = max(quadraticData$quadraticY),
    length.out = sampleSize))

quadraticNewData$quadraticY <- predict(
  quadraticModel,
  newdata = quadraticNewData)

plot(
  x = quadraticX,
  y = linearY,
  xlab = "",
  ylab = "",
  main = "Linear Association")

abline(
  lm(linearY ~ quadraticX),
  lwd = 2,
  col = "blue")

plot(
  x = quadraticData$quadraticX,
  y = quadraticData$quadraticY,
  xlab = "",
  ylab = "",
  main = "Nonlinear Association")

lines(
  quadraticNewData$quadraticY ~ quadraticNewData$quadraticX,
  lwd = 2,
  col = "blue")
```

If the shape of the association is nonlinear (as indicated by any of these plots), various approaches may be necessary such as including nonlinear terms (e.g., polynomial terms such as quadratic, cubic, quartic, or higher-degree terms), transforming the [predictors](#sec-correlationalStudy) (e.g., log, square root, inverse, exponential, Box-Cox, Yeo-Johnson transform), use of splines/piecewise regression, and generalized additive models.

#### Homoscedasticity {#sec-assumptionsRegressionEvaluatingHomoscedasticity}

To evaluate homoscedasticity, we can evaluate a residual plot (@fig-residualPlots) and spread-level plot (@fig-spreadLevelPlot).
A residual plot depicts the residuals on the y-axis as a function of the model's fitted values on the x-axis.
Homoscedasticity in a residual plot is identified as a constant spread of residuals versus fitted values—the residuals do not show a fan, cone, or bow-tie shape; a fan, cone, or bow-tie shape indicates heteroscedasticity.
In a residual plot, a fan or cone shape indicates increasing or decreasing variance in the residuals as a function of the fitted values; a bow-tie shape indicates that the residuals are smallest in the middle of the fitted values and greatest on the extremes of the fitted values.
A spread-level plot depicts the log of the absolute value of studentized residuals on the y-axis as a function of the log of the model's fitted values on the x-axis.
Homoscedasticity in a spread-level plot is identified as a flat slope; a slope that differs from zero indicates heteroscedasticity.

```{r}
#| layout: [[100], [50, 50], [50, 50]]
#| label: fig-homscedasticityHeteroscedasticity
#| fig-cap: "Example of Homoscedasticity and Heteroscedasticity in Residual Plots."
#| fig-alt: "Example of Homoscedasticity and Heteroscedasticity in Residual Plots."
#| fig-subcap:
#|   - "Homoscedasticity"
#|   - "Fan-Shaped Heteroscedasticity"
#|   - "Bow-Tie-Shaped Heteroscedasticity"
#|   - "Diamond-Shaped Heteroscedasticity"
#|   - "Triangle-Shaped Heteroscedasticity"
#| code-fold: true

set.seed(52242)
sampleSize <- 1000

# 1. Homoscedasticity
x1 <- runif(sampleSize, 0, 10)
y1 <- 3 + 2 * x1 + rnorm(sampleSize, mean = 0, sd = 2)
fit1 <- lm(y1 ~ x1)
res1 <- resid(fit1)
fitted1 <- fitted(fit1)

# 2. Fan-shaped heteroscedasticity
x2 <- runif(sampleSize, 0, 10)
y2 <- 3 + 2 * x2 + rnorm(sampleSize, mean = 0, sd = 0.5 * x2) # increasing variance
fit2 <- lm(y2 ~ x2)
res2 <- resid(fit2)
fitted2 <- fitted(fit2)

# 3. Bow-tie-shaped heteroscedasticity
x3 <- runif(sampleSize, 0, 10)
sd3 <- abs(x3 - 5) + 0.5  # variance smallest in middle, higher on edges
y3 <- 3 + 2 * x3 + rnorm(sampleSize, mean = 0, sd = sd3)
fit3 <- lm(y3 ~ x3)
res3 <- resid(fit3)
fitted3 <- fitted(fit3)

# 4. Diamond-shaped heteroscedasticity
x4 <- runif(sampleSize, 0, 10)
sd4 <- -abs(x4 - 5) + 5.5  # inverted bow-tie
y4 <- 3 + 2 * x4 + rnorm(sampleSize, mean = 0, sd = sd4)
fit4 <- lm(y4 ~ x4)
res4 <- resid(fit4)
fitted4 <- fitted(fit4)

#5. Triangle-shaped heteroscedasticity
height <- 10

sample_triangle <- function(n, v1, v2, v3) {
  u <- runif(n)
  v <- runif(n)
  is_flip <- u + v > 1
  u[is_flip] <- 1 - u[is_flip]
  v[is_flip] <- 1 - v[is_flip]
  
  x <- (1 - u - v) * v1[1] + u * v2[1] + v * v3[1]
  y <- (1 - u - v) * v1[2] + u * v2[2] + v * v3[2]
  
  cbind(x, y)
}

# Triangle vertices
v1 <- c(0, height)  # top left
v2 <- c(10, height) # top right
v3 <- c(5, 0)       # bottom center

# Sample points inside triangle
tri_points <- sample_triangle(
  sampleSize,
  v1,
  v2,
  v3)

# Extract x and residuals
x5 <- tri_points[, 1]
residuals5 <- tri_points[, 2]

# Generate outcome
y5 <- 3 + 2 * x5 + residuals5

# Fit model
fit5 <- lm(y5 ~ x5)
res5 <- resid(fit5)
fitted5 <- fitted(fit5)

# Plots
plot(
  fitted1,
  res1,
  main = "Homoscedasticity",
  xlab = "Fitted value",
  ylab = "Residual")

abline(
  h = 0,
  lwd = 2,
  col = "blue")

plot(
  fitted2,
  res2,
  main = "Fan-Shaped Heteroscedasticity",
  xlab = "Fitted value",
  ylab = "Residual")

abline(
  h = 0,
  lwd = 2,
  col = "blue")

plot(
  fitted3,
  res3,
  main = "Bow-Tie-Shaped Heteroscedasticity",
  xlab = "Fitted value",
  ylab = "Residual")

abline(
  h = 0,
  lwd = 2,
  col = "blue")

plot(
  fitted4,
  res4,
  main = "Diamond-Shaped Heteroscedasticity",
  xlab = "Fitted value",
  ylab = "Residual")

abline(
  h = 0,
  lwd = 2,
  col = "blue")

plot(
  fitted5,
  res5,
  main = "Triangle-Shaped Heteroscedasticity",
  xlab = "Fitted value",
  ylab = "Residual")

abline(
  h = 0,
  lwd = 2,
  col = "blue")
```

If there is heteroscedasticity, it may be necessary to transform the [outcome variable](#sec-correlationalStudy) to be more normally distributed.
The spread-level plot provides a suggested power transformation to transform the [outcome variable](#sec-correlationalStudy) so that the spread of residuals becomes more uniform across the fitted values.

#### Uncorrelated Residuals {#sec-assumptionsRegressionEvaluatingUncorrelatedResiduals}

To determine if residuals are correlated by a grouping level, we can examine the proportion of variance that is attributable to the grouping level using the intraclass correlation coefficient (ICC) from a [mixed model](#sec-mixedModels).
The greater the ICC value, the more variance is accounted for by the grouping level, and the more the residuals are intercorrelated.
If the residuals are intercorrelated, it may be necessary to account for the grouping structure of the data using a [mixed model](#sec-mixedModels).

#### Normally Distributed Residuals {#sec-assumptionsRegressionEvaluatingNormallyDistributedResiduals}

To examine whether residuals are normally distributed, we can examine quantile–quantile (QQ) plots and probability–probability (PP) plots.
QQ plots are particularly useful for identifying deviations from normality in the tails of the distribution; PP plots are particularly useful for identifying deviations from normality in the center of the distribution.
Researchers tend to be more concerned about the tails of the distribution, because extreme values tend to have a greater impact on inferences, so researchers tend to use QQ plots more often than PP plots.
Various examples of QQ plots and deviations from normality are depicted in @fig-distributionQQplots.
If the residuals are normally distributed, they will stay close to the diagonal reference line of the QQ and PP plots.

```{r}
#| layout-ncol: 2
#| label: fig-distributionQQplots
#| fig-cap: "Quantile–Quantile (QQ) Plots of Various Distributions (Right Side) with the Histogram of the Associated Distribution (Left Side)."
#| fig-alt: "Quantile–Quantile (QQ) Plots of Various Distributions (Right Side) with the Histogram of the Associated Distribution (Left Side)."
#| fig-subcap:
#|   - "Normal Distribution"
#|   - "Normal Distribution"
#|   - "Bimodal Distribution"
#|   - "Bimodal Distribution"
#|   - "Negatively Skewed Distribution"
#|   - "Negatively Skewed Distribution"
#|   - "Positively Skewed Distribution"
#|   - "Positively Skewed Distribution"
#|   - "Platykurtic (Light-Tailed) Distribution"
#|   - "Platykurtic (Light-Tailed) Distribution"
#|   - "Leptokurtic (Heavy-Tailed) Distribution"
#|   - "Leptokurtic (Heavy-Tailed) Distribution"
#| code-fold: true

set.seed(52242)

sampleSize <- 10000

distribution_normal <- rnorm(
  sampleSize,
  mean = 0,
  sd = 1)

distribution_bimodal <- c(
  rnorm(
    sampleSize/2,
    mean = -2,
    sd = 1),
  rnorm(
    sampleSize/2,
    mean = 2,
    sd = 1))

distribution_negativeSkew <- -rlnorm(
  sampleSize,
  meanlog = 0,
  sdlog = 1)

distribution_positiveSkew <- rlnorm(
  sampleSize,
  meanlog = 0,
  sdlog = 1)

distribution_lightTailed <- runif(
  sampleSize,
  min = -2,
  max = 2)

distribution_heavyTailed <- rt(
  sampleSize,
  df = 2)

hist(
  distribution_normal,
  main = "Normal Distribution",
  col = "#0099F8")

car::qqPlot(
  distribution_normal,
  main = "QQ Plot",
  id = FALSE)

hist(
  distribution_bimodal,
  main = "Bimodal Distribution",
  col = "#0099F8")

car::qqPlot(
  distribution_bimodal,
  main = "QQ Plot",
  id = FALSE)

hist(
  distribution_negativeSkew,
  main = "Negatively Skewed Distribution",
  col = "#0099F8")

car::qqPlot(
  distribution_negativeSkew,
  main = "QQ Plot",
  id = FALSE)

hist(
  distribution_positiveSkew,
  main = "Positively Skewed Distribution",
  col = "#0099F8")

car::qqPlot(
  distribution_positiveSkew,
  main = "QQ Plot",
  id = FALSE)

hist(
  distribution_lightTailed,
  main = "Platykurtic (Light Tailed) Distribution",
  col = "#0099F8")

car::qqPlot(
  distribution_lightTailed,
  main = "QQ Plot",
  id = FALSE)

hist(
  distribution_heavyTailed,
  main = "Leptokurtic (Heavy Tailed) Distribution",
  col = "#0099F8")

car::qqPlot(
  distribution_heavyTailed,
  main = "QQ Plot",
  id = FALSE)
```

If the residuals are not normally distributed (i.e., they do not stay close to the diagonal reference line of the QQ and PP plots), it may be necessary to transform the [outcome variable](#sec-correlationalStudy) to be more normally distributed or to use a generalized linear model (GLM) that more closely matches the distribution of the [outcome variable](#sec-correlationalStudy) (e.g., Poisson, binomial, gamma).

## How Much Variance the Model Explains {#sec-multipleRegressionExplainedVariance}

When estimating a multiple regression model, it can be useful to evaluate how much variance in the [outcome variable](#sec-correlationalStudy) that the [predictor variable(s)](#sec-correlationalStudy) explain (i.e., account for).
If the variables collectively explain only a small amount of variance, it suggest that the [predictor variables](#sec-correlationalStudy) have a small [effect size](#sec-practicalSignificance) and that other [predictor variables](#sec-correlationalStudy) will be necessary to account for the majority of variability in the [outcome variable](#sec-correlationalStudy).
There are two primary indices of how much how much variance in the [outcome variable](#sec-correlationalStudy) is explained by the [predictor variable(s)](#sec-correlationalStudy): the [coefficient of determination](#sec-multipleRegressionRSquared) ($R^2$) and [adjusted $R^2$](#sec-multipleRegressionAdjustedRsquared) ($R^2_{adj}$), described below.

### Coefficient of Determination ($R^2$) {#sec-multipleRegressionRSquared}

As noted in @sec-statisticalTestsPartitionedVariance, 
The coefficient of determination ($R^2$) reflects the proportion of variance in the [outcome (dependent) variable](#sec-correlationalStudy) that is explained by the model predictions, as in @eq-coefficientOfDeterminationPartitionedVariance: $R^2 = \frac{\text{variance explained in }Y}{\text{total variance in }Y}$.
Various formulas for $R^2$ are in @eq-rSquared.
Larger $R^2$ values indicate greater accuracy.
Multiple regression can be conceptualized with overlapping circles (similar to a venn diagram), where the non-overlapping portions of the circles reflect nonshared variance and the overlapping portions of the circles reflect shared variance, as in @fig-regression.

::: {#fig-regression}
![](images/multipleRegressionRSquared.png){width=50% fig-alt="Conceptual Depiction of Proportion of Variance Explained ($R^2$) in an Outcome Variable ($Y$) by Multiple Predictors ($X1$ and $X2$) in Multiple Regression. The size of each circle represents the variable's variance. The proportion of variance in $Y$ that is explained by the predictors is depicted by the areas in orange. The dark orange space ($G$) is where multiple predictors explain overlapping variance in the outcome. Overlapping variance that is explained in the outcome ($G$) will not be recovered in the regression coefficients when both predictors are included in the regression model. From @Petersen2024a and @PetersenPrinciplesPsychAssessment."}

Conceptual Depiction of Proportion of Variance Explained ($R^2$) in an Outcome Variable ($Y$) by Multiple Predictors ($X1$ and $X2$) in Multiple Regression. The size of each circle represents the variable's variance. The proportion of variance in $Y$ that is explained by the predictors is depicted by the areas in orange. The dark orange space ($G$) is where multiple predictors explain overlapping variance in the outcome. Overlapping variance that is explained in the outcome ($G$) will not be recovered in the regression coefficients when both predictors are included in the regression model. From @Petersen2024a and @PetersenPrinciplesPsychAssessment.
:::

One issue with $R^2$ is that it increases as the number of [predictors](#sec-correlationalStudy) increases, which can lead to [overfitting](#sec-overfitting) if using $R^2$ as an index to compare models for purposes of selecting the "best-fitting" model.
Consider the following example (adapted from @PetersenPrinciplesPsychAssessment) in which you have one [predictor variable](#sec-correlationalStudy) and one [outcome variable](#sec-correlationalStudy), as shown in @tbl-regression1.

```{r}
#| echo: false

regression1 <- data.frame(
  "y" = c(7, 13, 29, 10),
  "x1" = c(1, 2, 7, 2))

regression2 <- data.frame(
  "y" = c(7, 13, 29, 10),
  "x1" = c(1, 2, 7, 2),
  "x2" = c(3, 5, 1, 2))

regression1_model <- lm(
  y ~ x1,
  data = regression1)

regression1_intercept <- apa(regression1_model$coefficients[[1]], decimals = 2)
regression1_slope <- apa(regression1_model$coefficients[[2]], decimals = 2)
regression1_rsquare <- apa(summary(regression1_model)$r.squared, decimals = 2)

regression2_model <- lm(y ~ x1 + x2, data = regression2)
regression2_intercept <- apa(regression2_model$coefficients[[1]], decimals = 2)
regression2_slope1 <- apa(regression2_model$coefficients[[2]], decimals = 2)
regression2_slope2 <- apa(regression2_model$coefficients[[3]], decimals = 2)
regression2_rsquare <- apa(summary(regression2_model)$r.squared, decimals = 2)
```

```{r}
#| label: tbl-regression1
#| tbl-cap: "Example Data of Predictor (x1) and Outcome (y) Used for Regression Model."
#| echo: false

knitr::kable(
  regression1,
  col.names = c("y","x1"),
  booktabs = TRUE)
```

Using the data, the best fitting regression model is: $y =$ `{r} regression1_intercept` $+$ `{r} regression1_slope` $\cdot x_1$.
In this example, the $R^2$ is `{r} regression1_rsquare`.
The equation is not a perfect prediction, but with a single [predictor variable](#sec-correlationalStudy), it captures the majority of the variance in the [outcome](#sec-correlationalStudy).

Now consider the following example where you add a second [predictor variable](#sec-correlationalStudy) to the data above, as shown in @tbl-regression2.

```{r}
#| label: tbl-regression2
#| tbl-cap: "Example Data of Predictors (x1 and x2) and Outcome (y) Used for Regression Model."
#| echo: false

knitr::kable(
  regression2,
  col.names = c("y","x1","x2"),
  booktabs = TRUE)
```

With the second [predictor variable](#sec-correlationalStudy), the best fitting regression model is: $y =$ `{r} regression2_intercept` + `{r} regression2_slope1` $\cdot x_1 +$ `{r} regression2_slope2` $\cdot x_2$.
In this example, the $R^2$ is `{r} regression2_rsquare`.
The equation with the second [predictor variable](#sec-correlationalStudy) provides a perfect prediction of the [outcome](#sec-correlationalStudy).

Providing perfect prediction with the right set of [predictor variable](#sec-correlationalStudy)s is the dream of multiple regression.
So, using multiple regression, we often add [predictor variables](#sec-correlationalStudy) to incrementally improve prediction.
Knowing how much variance would be accounted for by random chance follows @eq-predictionByChance:

$$
E(R^2) = \frac{K}{n-1}
$$ {#eq-predictionByChance}

where $E(R^2)$ is the expected value of $R^2$ (the proportion of variance explained), $K$ is the number of [predictor variables](#sec-correlationalStudy), and $n$ is the sample size.
The formula demonstrates that the more [predictor variables](#sec-correlationalStudy) in the regression model, the more variance will be accounted for by chance.
With many [predictor variables](#sec-correlationalStudy) and a small sample, you can account for a large share of the variance merely by chance.

As an example, consider that we have 13 [predictor variables](#sec-correlationalStudy) to predict fantasy performance for 43 players.
Assume that, with 13 [predictor variables](#sec-correlationalStudy), we explain 38% of the variance ($R^2 = .38; r = .62$).
We explained a lot of the variance in the [outcome](#sec-correlationalStudy), but it is important to consider how much variance could have been explained by random chance: $E(R^2) = \frac{K}{n-1} = \frac{13}{43 - 1} = .31$.
We expect to explain 31% of the variance, by chance, in the [outcome](#sec-correlationalStudy).
So, 82% of the variance explained was likely spurious (i.e., $\frac{.31}{.38} = .82$).
As the sample size increases, the spuriousness decreases.
To account for the number of [predictor variables](#sec-correlationalStudy) in the model, we can use a modified version of $R^2$ called adjusted $R^2$ ($R^2_{adj}$), described next.

### Adjusted $R^2$ ($R^2_{adj}$) {#sec-multipleRegressionAdjustedRsquared}

Adjusted $R^2$ ($R^2_{adj}$) accounts for the number of [predictor variables](#sec-correlationalStudy) in the model, based on how much would be expected to be accounted for by chance to penalize [overfitting](#sec-overfitting).
Adjusted $R^2$ ($R^2_{adj}$) reflects the proportion of variance in the [outcome (dependent) variable](#sec-correlationalStudy) that is explained by the model predictions over and above what would be expected to be accounted for by chance, given the number of [predictor variables](#sec-correlationalStudy) in the model.
The formula for adjusted $R^2$ ($R^2_{adj}$) is in @eq-adjustedRSquared:

$$
R^2_{adj} = 1 - (1 - R^2) \frac{n - 1}{n - p - 1}
$$ {#eq-adjustedRSquared}

where $p$ is the number of [predictor variables](#sec-correlationalStudy) in the model, and $n$ is the sample size.

## Overfitting {#sec-overfitting}

Statistical models applied to big data (e.g., data with many [predictor variables](#sec-correlationalStudy)) can *overfit* the data, which means that the statistical model accounts for error variance, which will not generalize to future samples.
So, even though an overfitting statistical model appears to be accurate because it is accounting for more variance, it is not actually that accurate—it will predict new data less accurately than how accurately it accounts for the data with which the model was built.
In the case of fantasy football analytics, this is especially relevant because there are hundreds if not thousands of variables we could consider for inclusion and many, many players when considering historical data.

Consider an example where you develop an algorithm to predict players' fantasy performance based on 2024 data using hundreds of [predictor variables](#sec-correlationalStudy).
To some extent, these [predictor variables](#sec-correlationalStudy) will likely account for true variance (i.e., signal) and error variance (i.e., noise).
If we were to apply the same algorithm based on the `r as.integer(format(Sys.Date(), "%Y")) - 1` prediction model to `r as.integer(format(Sys.Date(), "%Y"))` data, the prediction model would likely predict less accurately than with `r as.integer(format(Sys.Date(), "%Y")) - 1` data.
The regression coefficients tend to become weaker when applied to new data, a phenomenon called [shrinkage](#sec-shrinkage), which is described in @sec-shrinkage.
The regression coefficients in the [FILL IN]

In @fig-overfittingModel, the blue line represents the true distribution of the data, and the red line is an overfitting model:

```{r}
#| label: fig-overfittingModel
#| fig-cap: "Over-fitting Model in Red Relative to the True Distribution of the Data in Blue. From @Petersen2024a and @PetersenPrinciplesPsychAssessment."
#| fig-alt: "Over-fitting Model in Red Relative to the True Distribution of the Data in Blue. From @Petersen2024a and @PetersenPrinciplesPsychAssessment."
#| code-fold: true

set.seed(52242)

sampleSize <- 200
quadraticX <- rnorm(sampleSize)
quadraticY <- quadraticX ^ 2 + rnorm(sampleSize)
quadraticData <- cbind(quadraticX, quadraticY) %>%
  data.frame %>%
  arrange(quadraticX)

quadraticModel <- lm(
  quadraticY ~ quadraticX + I(quadraticX ^ 2),
  data = quadraticData)

quadraticNewData <- data.frame(
  quadraticX = seq(
    from = min(quadraticData$quadraticX),
    to = max(quadraticData$quadraticY),
    length.out = sampleSize))

quadraticNewData$quadraticY <- predict(
  quadraticModel,
  newdata = quadraticNewData)

loessFit <- loess(
  quadraticY ~ quadraticX,
  data = quadraticData,
  span = 0.01,
  degree = 1)

loessNewData <- data.frame(
  quadraticX = seq(
    from = min(quadraticData$quadraticX),
    to = max(quadraticData$quadraticY),
    length.out = sampleSize))

quadraticNewData$loessY <- predict(
  loessFit,
  newdata = quadraticNewData)

plot(
  x = quadraticData$quadraticX,
  y = quadraticData$quadraticY,
  xlab = "",
  ylab = "")

lines(
  quadraticNewData$quadraticY ~ quadraticNewData$quadraticX,
  lwd = 2,
  col = "blue")

lines(
  quadraticNewData$loessY ~ quadraticNewData$quadraticX,
  lwd = 2,
  col = "red")
```

## Covariates {#sec-covariates}

Covariates are variables that you include in the statistical model to try to control for them so you can better isolate the unique contribution of the [predictor variable](#sec-correlationalStudy)(s) in relation to the [outcome variable](#sec-correlationalStudy).
Use of covariates examines the association between the [predictor variable](#sec-correlationalStudy) and the [outcome variable](#sec-correlationalStudy) when holding people's level constant on the covariates.
Inclusion of [confounds](#sec-causalDiagramConfounding) as covariates allows potentially gaining a more accurate estimate of the causal effect of the [predictor variable](#sec-correlationalStudy) on the [outcome variable](#sec-correlationalStudy).
Ideally, you want to include any and all [confounds](#sec-causalDiagramConfounding) as covariates.
As described in @sec-correlationCausation, [confounds](#sec-causalDiagramConfounding) are third variables that influence both the [predictor variable](#sec-correlationalStudy) and the [outcome variable](#sec-correlationalStudy) and explain their association.
Covariates are potentially (but not necessarily) [confounds](#sec-causalDiagramConfounding).
For instance, you might include the player's age as a covariate in a model that examines whether a player's 40-yard dash time at the NFL Combine predicts their fantasy points in their rookie year, but it may not be a [confound](#sec-causalDiagramConfounding).

## Example: Predicting Wide Receivers' Fantasy Points {#sec-multipleRegressionFantasyPointsWRs}

Let's say we want to use a number of variables to predict a wide receiver's fantasy performance.
We want to consider several [predictors](#sec-correlationalStudy), including the player's age, height, weight, and target share.
Target share is computed as the number of targets a player receives divided by the team's total number of targets.
We have only a few [predictors](#sec-correlationalStudy) and our sample size is large enough such that [overfitting](#sec-overfitting) is not likely a concern.

### Examine Descriptive Statistics {#sec-multipleRegressionFantasyPointsWRsDescriptive}

Let's first examine [descriptive statistics](#sec-descriptiveStatistics) of the predictor and outcome variables.

```{r}
player_stats_seasonal %>% 
  dplyr::select(fantasyPoints, age, height, weight, target_share) %>% 
  dplyr::summarise(across(
      everything(),
      .fns = list(
        n = ~ length(na.omit(.)),
        missingness = ~ mean(is.na(.)) * 100,
        M = ~ mean(., na.rm = TRUE),
        SD = ~ sd(., na.rm = TRUE),
        min = ~ min(., na.rm = TRUE),
        max = ~ max(., na.rm = TRUE),
        range = ~ max(., na.rm = TRUE) - min(., na.rm = TRUE),
        IQR = ~ IQR(., na.rm = TRUE),
        MAD = ~ mad(., na.rm = TRUE),
        median = ~ median(., na.rm = TRUE),
        pseudomedian = ~ DescTools::HodgesLehmann(., na.rm = TRUE),
        mode = ~ petersenlab::Mode(., multipleModes = "mean"),
        skewness = ~ psych::skew(., na.rm = TRUE),
        kurtosis = ~ psych::kurtosi(., na.rm = TRUE)),
      .names = "{.col}.{.fn}")) %>%
    tidyr::pivot_longer(
      cols = everything(),
      names_to = c("variable","index"),
      names_sep = "\\.") %>% 
    tidyr::pivot_wider(
      names_from = index,
      values_from = value)
```

Let's also examine the distributions of the variables using a [density plot](#sec-ridgelinePlot), as depicted in @fig-densityPlotMultipleRegressionVars.

```{r}
#| layout: [[100], [50, 50], [50, 50]]
#| label: fig-densityPlotMultipleRegressionVars
#| fig-cap: "Density Plot of Model Variables (i.e., Predictor and Outcome Variables)."
#| fig-alt: "Density Plot of Model Variables (i.e., Predictor and Outcome Variables)."
#| fig-subcap:
#|   - "Fantasy Points"
#|   - "Age"
#|   - "Height"
#|   - "Weight"
#|   - "Target Share"

ggplot2::ggplot(
  data = player_stats_seasonal %>%
    filter(position_group %in% c("WR")),
  mapping = aes(
    x = fantasyPoints)
) +
  geom_histogram(
    aes(y = after_stat(density)),
    color = "#000000",
    fill = "#0099F8"
  ) +
  geom_density(
    color = "#000000",
    fill = "#F85700",
    alpha = 0.6 # add transparency
  ) +
  geom_rug() +
  labs(
    x = "Fantasy Points",
    y = "Density",
    title = "Density Plot of Fantasy Points with Histogram and Rug Plot"
  ) +
  theme_classic() +
  theme(axis.title.y = element_text(angle = 0, vjust = 0.5)) # horizontal y-axis title

ggplot2::ggplot(
  data = player_stats_seasonal %>%
    filter(position_group %in% c("WR")),
  mapping = aes(
    x = age)
) +
  geom_histogram(
    aes(y = after_stat(density)),
    color = "#000000",
    fill = "#0099F8"
  ) +
  geom_density(
    color = "#000000",
    fill = "#F85700",
    alpha = 0.6 # add transparency
  ) +
  geom_rug() +
  labs(
    x = "Age (years)",
    y = "Density",
    title = "Density Plot of Player Age with Histogram and Rug Plot"
  ) +
  theme_classic() +
  theme(axis.title.y = element_text(angle = 0, vjust = 0.5)) # horizontal y-axis title

ggplot2::ggplot(
  data = player_stats_seasonal %>%
    filter(position_group %in% c("WR")),
  mapping = aes(
    x = height)
) +
  geom_histogram(
    aes(y = after_stat(density)),
    color = "#000000",
    fill = "#0099F8"
  ) +
  geom_density(
    color = "#000000",
    fill = "#F85700",
    alpha = 0.6 # add transparency
  ) +
  geom_rug() +
  labs(
    x = "Height (inches)",
    y = "Density",
    title = "Density Plot of Player Height with Histogram and Rug Plot"
  ) +
  theme_classic() +
  theme(axis.title.y = element_text(angle = 0, vjust = 0.5)) # horizontal y-axis title

ggplot2::ggplot(
  data = player_stats_seasonal %>%
    filter(position_group %in% c("WR")),
  mapping = aes(
    x = weight)
) +
  geom_histogram(
    aes(y = after_stat(density)),
    color = "#000000",
    fill = "#0099F8"
  ) +
  geom_density(
    color = "#000000",
    fill = "#F85700",
    alpha = 0.6 # add transparency
  ) +
  geom_rug() +
  labs(
    x = "Weight (pounds)",
    y = "Density",
    title = "Density Plot of Player Weight with Histogram and Rug Plot"
  ) +
  theme_classic() +
  theme(axis.title.y = element_text(angle = 0, vjust = 0.5)) # horizontal y-axis title

ggplot2::ggplot(
  data = player_stats_seasonal %>%
    filter(position_group %in% c("WR")),
  mapping = aes(
    x = target_share)
) +
  geom_histogram(
    aes(y = after_stat(density)),
    color = "#000000",
    fill = "#0099F8"
  ) +
  geom_density(
    color = "#000000",
    fill = "#F85700",
    alpha = 0.6 # add transparency
  ) +
  geom_rug() +
  labs(
    x = "Target Share",
    y = "Density",
    title = "Density Plot of Target Share with Histogram and Rug Plot"
  ) +
  theme_classic() +
  theme(axis.title.y = element_text(angle = 0, vjust = 0.5)) # horizontal y-axis title
```

### Examine Bivariate Associations {#sec-multipleRegressionFantasyPointsWRsBivariate}

Then, let's examine the bivariate association of each using a [scatterplot](#sec-scatterplot) to evaluate for any potential nonlinearity, as depicted in @fig-scatterplots.

```{r}
#| layout-ncol: 2
#| label: fig-scatterplots
#| fig-cap: "Scatterplots With Fantasy Points (Season) Among Wide Receivers. The linear best-fit line is in black. The nonlinear best-fit line is in blue."
#| fig-alt: "Scatterplots With Fantasy Points (Season) Among Wide Receivers. The linear best-fit line is in black. The nonlinear best-fit line is in blue."
#| fig-subcap:
#|   - "Age"
#|   - "Height"
#|   - "Weight"
#|   - "Target Share"

ggplot2::ggplot(
  data = player_stats_seasonal %>% filter(position %in% c("WR")),
  aes(
    x = age,
    y = fantasyPoints)) +
  geom_point(alpha = 0.05) +
  geom_smooth(
    method = "lm",
    color = "black") +
  geom_smooth() +
  coord_cartesian(
    ylim = c(0,NA),
    expand = FALSE) +
  labs(
    x = "Player Age (Years)",
    y = "Fantasy Points (Season)",
    title = "Fantasy Points (Season) by Player Age",
    subtitle = "(Among Wide Receivers)"
  ) +
  theme_classic()

ggplot2::ggplot(
  data = player_stats_seasonal %>% filter(position %in% c("WR")),
  aes(
    x = height,
    y = fantasyPoints)) +
  geom_point(alpha = 0.05) +
  geom_smooth(
    method = "lm",
    color = "black") +
  geom_smooth() +
  coord_cartesian(
    ylim = c(0,NA),
    expand = FALSE) +
  labs(
    x = "Player Height (Inches)",
    y = "Fantasy Points (Season)",
    title = "Fantasy Points (Season) by Player Height",
    subtitle = "(Among Wide Receivers)"
  ) +
  theme_classic()

ggplot2::ggplot(
  data = player_stats_seasonal %>% filter(position %in% c("WR")),
  aes(
    x = weight,
    y = fantasyPoints)) +
  geom_point(alpha = 0.05) +
  geom_smooth(
    method = "lm",
    color = "black") +
  geom_smooth() +
  coord_cartesian(
    ylim = c(0,NA),
    expand = FALSE) +
  labs(
    x = "Player Weight (Pounds)",
    y = "Fantasy Points (Season)",
    title = "Fantasy Points (Season) by Player Weight",
    subtitle = "(Among Wide Receivers)"
  ) +
  theme_classic()

ggplot2::ggplot(
  data = player_stats_seasonal %>% filter(position %in% c("WR")),
  aes(
    x = target_share,
    y = fantasyPoints)) +
  geom_point(alpha = 0.05) +
  geom_smooth(
    method = "lm",
    color = "black") +
  geom_smooth() +
  coord_cartesian(
    ylim = c(0,NA),
    expand = FALSE) +
  labs(
    x = "Target Share",
    y = "Fantasy Points (Season)",
    title = "Fantasy Points (Season) by Target Share",
    subtitle = "(Among Wide Receivers)"
  ) +
  theme_classic()
```

There are some suggestions of potential nonlinearity, such as an inverted-U-shaped association between height and fantasy points, suggesting that there may an optimal range for height among Wide Receivers—being too short or too tall could be a disadvantage.
In addition, target share shows a weakening association as target share increases.
Thus, after evaluating the linear association between the [predictors](#sec-correlationalStudy) and [outcome](#sec-correlationalStudy), we will also examine the possibility for curvilinear associations.

### Estimate Multiple Regression Model {#sec-multipleRegressionFantasyPointsWRsModel}

Now that we have examined [descriptive statistics](#sec-descriptiveStatistics) and bivariate associations, let's first estimate a multiple regression model with only linear terms:

```{r}
linearRegressionModel <- lm(
  fantasyPoints ~ age + height + weight + target_share,
  data = player_stats_seasonal %>% filter(position %in% c("WR")),
  na.action = "na.exclude"
)
```

The model formula is in @eq-linearRegressionModel:

$$
\text{fantasy points} = \beta_0 + \beta_1 \cdot \text{age} + \beta_2 \cdot \text{height} + \beta_3 \cdot \text{weight} + \beta_4 \cdot \text{target share} + \epsilon
$$ {#eq-linearRegressionModel}

Here are the model results:

```{r}
summary(linearRegressionModel)
```

The only terms that were significantly associated with fantasy performance among Wide Receivers are weight and target share, both of which showed a positive association with fantasy points.

We can obtain the [coefficient of determination](#sec-multipleRegressionRSquared) ($R^2$) and [adjusted $R^2$](#sec-multipleRegressionAdjustedRsquared) ($R^2_{adj}$) using the following code:

```{r}
summary(linearRegressionModel)$r.squared
summary(linearRegressionModel)$adj.r.squared
```

```{r}
#| include: false

linearRegressionModel_rsquared <- summary(linearRegressionModel)$r.squared
```

The model explained `r petersenlab::apa(linearRegressionModel_rsquared * 100, decimals = 0)`% of the variability in fantasy points (i.e., $R^2 = `r petersenlab::apa(linearRegressionModel_rsquared, decimals = 2, leading = FALSE)`$).

```{r}
#| include: false

linearRegressionModel_beta0 <- coef(linearRegressionModel)[["(Intercept)"]]
linearRegressionModel_beta1 <- coef(linearRegressionModel)[["age"]]
linearRegressionModel_beta2 <- coef(linearRegressionModel)[["height"]]
linearRegressionModel_beta3 <- coef(linearRegressionModel)[["weight"]]
linearRegressionModel_beta4 <- coef(linearRegressionModel)[["target_share"]]
```

The model formula with substituted values is in @eq-linearRegressionModelSubstitute:

$$
\begin{aligned}
  \text{fantasy points} = &\beta_0 + \beta_1 \cdot \text{age} + \beta_2 \cdot \text{height} + \beta_3 \cdot \text{weight} + \beta_4 \cdot \text{target share} + \epsilon \\
  = &`r petersenlab::apa(linearRegressionModel_beta0, decimals = 2)` + `r petersenlab::apa(linearRegressionModel_beta1, decimals = 2)` \cdot \text{age} + `r petersenlab::apa(linearRegressionModel_beta2, decimals = 2)` \cdot \text{height} + `r petersenlab::apa(linearRegressionModel_beta3, decimals = 2)` \cdot \text{weight} + `r petersenlab::apa(linearRegressionModel_beta4, decimals = 2)` \cdot \text{target share} + \epsilon
\end{aligned}
$$ {#eq-linearRegressionModelSubstitute}

If we want to obtain standardized regression coefficients, we can use the `standardize_parameters()` function of the `effectsize` package [@R-effectsize; @BenShachar2020_packages].

```{r}
print(effectsize::standardize_parameters(linearRegressionModel, method = "basic"), digits = 2)
```

Or, we can standardize the [outcome variable](#sec-correlationalStudy) and each [predictor variable](#sec-correlationalStudy) using the `scale()` function:

```{r}
linearRegressionModelStandardized <- lm(
  scale(fantasyPoints) ~ scale(age) + scale(height) + scale(weight) + scale(target_share),
  data = player_stats_seasonal %>% filter(position %in% c("WR")),
  na.action = "na.exclude"
)

summary(linearRegressionModelStandardized)

print(effectsize::standardize_parameters(linearRegressionModel, method = "refit"), digits = 2)
```

Target share has a large [effect size](#sec-practicalSignificance).
All of the other [predictors](#sec-correlationalStudy) have a small [effect size](#sec-practicalSignificance).

Now let's consider whether any of the terms show curvilinear associations with fantasy points by adding quadratic terms:

```{r}
quadraticTermsRegressionModel <- lm(
  fantasyPoints ~ age + I(age^2) + height + I(height^2) + weight + I(weight^2) + target_share + I(target_share^2),
  data = player_stats_seasonal %>% filter(position %in% c("WR")),
  na.action = "na.exclude"
)
```

The model formula is in @eq-quadraticTermsRegressionModel:

$$
\begin{aligned}
  \text{fantasy points} \; = \; &\beta_0 + \beta_1 \cdot \text{age} + \beta_2 \cdot \text{age}^2 + \beta_3 \cdot \text{height} + \beta_4 \cdot \text{height}^2 + \\
  &\beta_5 \cdot \text{weight} + \beta_6 \cdot \text{weight}^2 + \beta_7 \cdot \text{target share} + \beta_8 \cdot \text{target share}^2 + \epsilon
\end{aligned}
$$ {#eq-quadraticTermsRegressionModel}

Here are the model results:

```{r}
summary(quadraticTermsRegressionModel)
```

Only the quadratic term for target share (not height or weight) shows a significant association.

Here are the standardized coefficients:

```{r}
print(effectsize::standardize_parameters(quadraticTermsRegressionModel, method = "basic"), digits = 2)
```

```{r}
quadraticTermsRegressionModelStandardized <- lm(
  scale(fantasyPoints) ~ scale(age) + scale(I(age^2)) + scale(height) + scale(I(height^2)) + scale(weight) + scale(I(weight^2)) + scale(target_share) + scale(I(target_share^2)),
  data = player_stats_seasonal %>% filter(position %in% c("WR")),
  na.action = "na.exclude"
)

summary(quadraticTermsRegressionModelStandardized)

print(effectsize::standardize_parameters(quadraticTermsRegressionModel, method = "refit"), digits = 2)
```

### Dominance Analysis {#sec-multipleRegressionDominanceAnalysis}

We can perform a dominance analysis to evaluate the relative importance of the predictors in the regression model.
To perform the dominance analysis, we use the `dominance_analysis()` function of the `parameters` package [@R-parameters; @Luedecke2020_packages], which leverages the `domir` package [@R-domir].

```{r}
parameters::dominance_analysis(linearRegressionModel)
```

### Visualizing Regression Results {#sec-multipleRegressionVisualizingResults}

#### Regression Coefficients {#sec-multipleRegressionVisualizingRegressionCoefficients}

To visualize the regression coefficients, we can use the `tidy()` function of the `broom` package [@R-broom], as in Figures [-@fig-regressionCoefficients] and [-@fig-regressionCoefficientsStandardized].

```{r}
quadraticTermsRegressionModel_tidy <- broom::tidy(
  quadraticTermsRegressionModel,
  conf.int = TRUE)

quadraticTermsRegressionModelStandardized_tidy <- broom::tidy(
  quadraticTermsRegressionModelStandardized,
  conf.int = TRUE)
```

```{r}
#| label: fig-regressionCoefficients
#| fig-cap: "Regression Coefficients with 95% Confidence Interval."
#| fig-alt: "Regression Coefficients with 95% Confidence Interval."

ggplot2::ggplot(
  data = quadraticTermsRegressionModel_tidy,
  aes(
    x = term,
    y = estimate)) +
  geom_point() +
  geom_errorbar(
    aes(
      ymin = conf.low,
      ymax = conf.high),
    width = 0.2) +
  coord_flip() + # flip axes for readability
  labs(
    title = "Regression Coefficients with 95% CI",
    x = "Predictor",
    y = "Coefficient Estimate") +
  theme_minimal()
```

```{r}
#| label: fig-regressionCoefficientsStandardized
#| fig-cap: "Standardized Regression Coefficients with 95% Confidence Interval."
#| fig-alt: "Standardized Regression Coefficients with 95% Confidence Interval."

ggplot2::ggplot(
  data = quadraticTermsRegressionModelStandardized_tidy,
  aes(
    x = term,
    y = estimate)) +
  geom_point() +
  geom_errorbar(
    aes(
      ymin = conf.low,
      ymax = conf.high),
    width = 0.2) +
  coord_flip() + # flip axes for readability
  labs(
    title = "Standardized Regression Coefficients with 95% CI",
    x = "Predictor",
    y = "Standardized Coefficient Estimate") +
  theme_minimal()
```

#### Model-Implied Association {#sec-multipleRegressionVisualizingModelImpliedAssociation}

If we wanted to visualize the shape of the model-implied association between target share and fantasy points, we could generate the model-implied predictions using the data range that we want to visualize.

```{r}
newdata <- data.frame(
  target_share = seq(
    from = min(player_stats_seasonal$target_share[which(player_stats_seasonal$position == "WR")], na.rm = TRUE),
    to = max(player_stats_seasonal$target_share[which(player_stats_seasonal$position == "WR")], na.rm = TRUE),
    length.out = 1000
  )
)

newdata$age <- mean(player_stats_seasonal$age[which(player_stats_seasonal$position == "WR")], na.rm = TRUE)
newdata$height <- mean(player_stats_seasonal$height[which(player_stats_seasonal$position == "WR")], na.rm = TRUE)
newdata$weight <- mean(player_stats_seasonal$weight[which(player_stats_seasonal$position == "WR")], na.rm = TRUE)
```

```{r}
newdata$fantasyPoints <- predict(
  quadraticTermsRegressionModel,
  newdata = newdata
)
```

We can depict the model-implied predictions of fantasy points as a function of target share, as shown in @fig-modelImpliedPredictionsQuadraticRegression.

```{r}
#| label: fig-modelImpliedPredictionsQuadraticRegression
#| fig-cap: "Model-Implied Predictions of A Wide Receiver's Fantasy Points as a Function of Target Share. The model-implied predictions were estimated based on a multiple regression model."
#| fig-alt: "Model-Implied Predictions of A Wide Receiver's Fantasy Points as a Function of Target Share. The model-implied predictions were estimated based on a multiple regression model."

ggplot2::ggplot(
  data = newdata,
  aes(
    x = target_share,
    y = fantasyPoints)) +
  geom_smooth() +
  coord_cartesian(
    ylim = c(0,NA),
    expand = FALSE) +
  labs(
    x = "Target Share",
    y = "Fantasy Points (Season)",
    title = "Fantasy Points (Season) by Target Share",
    subtitle = "(Among Wide Receivers)"
  ) +
  theme_classic()
```

We could also generate the model-implied prediction of fantasy points for any value of the [predictor variables](#sec-correlationalStudy).
For instance, here are the number of fantasy points expected for a Wide Receiver who is 23 years old, is 6'2" tall (72 inches), weighs 200 pounds, and has a target share of 50% (i.e., 0.5):

```{r}
predict(
  quadraticTermsRegressionModel,
  newdata = data.frame(
    age = 23,
    height = 72,
    weight = 200,
    target_share = .5
  )
)
```

```{r}
#| include: false

predictedValue <- predict(
  quadraticTermsRegressionModel,
  newdata = data.frame(
    age = 23,
    height = 72,
    weight = 200,
    target_share = .5
  )
)
```

The player would be expected to score `r petersenlab::apa(predictedValue, decimals = 0)` fantasy points.

We can calculate this by substituting in the regression coefficients and predictor values.
Here is the computation:

```{r}
age <- 23
height <- 72
weight <- 200
target_share <- .5

beta0 <- coef(quadraticTermsRegressionModel)[["(Intercept)"]]
beta1 <- coef(quadraticTermsRegressionModel)[["age"]]
beta2 <- coef(quadraticTermsRegressionModel)[["I(age^2)"]]
beta3 <- coef(quadraticTermsRegressionModel)[["height"]]
beta4 <- coef(quadraticTermsRegressionModel)[["I(height^2)"]]
beta5 <- coef(quadraticTermsRegressionModel)[["weight"]]
beta6 <- coef(quadraticTermsRegressionModel)[["I(weight^2)"]]
beta7 <- coef(quadraticTermsRegressionModel)[["target_share"]]
beta8 <- coef(quadraticTermsRegressionModel)[["I(target_share^2)"]]

predictedFantasyPoints <- beta0 + beta1*age + beta2*(age^2) + beta3*height + beta4*(height^2) + beta5*weight + beta6*(weight^2) + beta7*target_share + beta8*(target_share^2)
predictedFantasyPoints
```

The model formula with substituted values is in @eq-quadraticTermsRegressionModelSubstitute:

$$
\begin{aligned}
  \text{fantasy points} \; = \; &\beta_0 + \beta_1 \cdot \text{age} + \beta_2 \cdot \text{age}^2 + \beta_3 \cdot \text{height} + \beta_4 \cdot \text{height}^2 + \\
  &\beta_5 \cdot \text{weight} + \beta_6 \cdot \text{weight}^2 + \beta_7 \cdot \text{target share} + \beta_8 \cdot \text{target share}^2 + \epsilon \\
  = &`r petersenlab::apa(beta0, decimals = 2)` + `r petersenlab::apa(beta1, decimals = 2)` \cdot `r petersenlab::apa(age, decimals = 0)` + `r petersenlab::apa(beta2, decimals = 2)` \cdot `r petersenlab::apa(age, decimals = 0)`^2 + `r petersenlab::apa(beta3, decimals = 2)` \cdot `r petersenlab::apa(height, decimals = 0)` + `r petersenlab::apa(beta4, decimals = 2)` \cdot `r petersenlab::apa(height, decimals = 0)`^2 + \\
  &`r petersenlab::apa(beta5, decimals = 2)` \cdot `r petersenlab::apa(weight, decimals = 0)` + `r petersenlab::apa(beta6, decimals = 2)` \cdot `r petersenlab::apa(weight, decimals = 0)`^2 + `r petersenlab::apa(beta7, decimals = 2)` \cdot `r petersenlab::apa(target_share, decimals = 0)` + `r petersenlab::apa(beta8, decimals = 2)` \cdot `r petersenlab::apa(target_share, decimals = 0)`^2 + \epsilon \\
  = &`r petersenlab::apa(predictedFantasyPoints, decimals = 2)`
\end{aligned}
$$ {#eq-quadraticTermsRegressionModelSubstitute}

### Evaluating and Addressing Assumptions {#sec-multipleRegressionExamplesAddressingAssumptions}

The assumptions for multiple regression are described in @sec-assumptionsRegression.
I describe ways to evaluate assumptions in @sec-assumptionsRegressionEvaluating.

As a reminder, here are four assumptions:

- there is a linear association between the [predictor variables](#sec-correlationalStudy) and the [outcome variable](#sec-correlationalStudy)
- there is homoscedasticity of the residuals; the residuals do not differ as a function of the [predictor variables](#sec-correlationalStudy) or as a function of the [outcome variable](#sec-correlationalStudy)
- the residuals are independent; they are uncorrelated with each other
- the residuals are normally distributed

#### Linear Association {#sec-multipleRegressionExamplesAddressingAssumptionsLinearAssociation}

We evaluated the shape of the association between the [predictor variables](#sec-correlationalStudy) and the [outcome variables](#sec-correlationalStudy) using [scatterplots](#sec-scatterplot).
We accounted for potential curvilinearity in the associations with a quadratic term.
Other ways to account for nonlinearity, in addition to polynomials, include transforming [predictors](#sec-correlationalStudy), use of splines/piecewise regression, and generalized additive models.

To evaluate for potential nonlinearity in the associations, we can also evaluate residual plots (@fig-residualPlots), marginal model plots (@fig-marginalModelPlots), added-variable plots (@fig-addedVariablePlots), and component-plus-residual plots (@fig-componentPlusResidualPlots) from the `car` package [@Fox2019_packages; @R-car].
For evaluating linearity, we would expect minimal bend/curvature in the lines.

```{r}
#| label: fig-marginalModelPlots
#| fig-cap: "Marginal Model Plots."
#| fig-alt: "Marginal Model Plots."

car::marginalModelPlots(
  quadraticTermsRegressionModel,
  sd = TRUE,
  id = TRUE)
```

```{r}
#| label: fig-addedVariablePlots
#| fig-cap: "Added-Variable Plots."
#| fig-alt: "Added-Variable Plots."

car::avPlots(
  quadraticTermsRegressionModel,
  id = TRUE)
```

```{r}
#| label: fig-componentPlusResidualPlots
#| fig-cap: "Component-Plus-Residual Plots."
#| fig-alt: "Component-Plus-Residual Plots."

car::crPlots(
  quadraticTermsRegressionModel,
  sd = TRUE,
  id = TRUE)
```

The marginal model plots (@fig-marginalModelPlots), residual plots (@fig-residualPlots), and  component-plus-residual plots (@fig-componentPlusResidualPlots) suggest that the nonlinearity of the association between target share and fantasy points may not be fully captured by the quadratic term.
Thus, we may need to apply a different approach to handling the nonlinear association between target share and fantasy points.

One approach we can take is to transform the `target_shares` variable to be more normally distributed.

The histogram for the raw `target_shares` variable is in @fig-histogramTargetShare.

```{r}
#| label: fig-histogramTargetShare
#| fig-cap: "Histogram of Target Share."
#| fig-alt: "Histogram of Target Share."

hist(
  player_stats_seasonal$target_share[which(player_stats_seasonal$position == "WR")],
  main = "Histogram of Target Share")
```

The variable shows a strong positive skew.
To address a strong positive skew, we can use a log transformation.
The histogram of the log-transformed variable is in @fig-histogramTargetSharesTransformed.

```{r}
#| label: fig-histogramTargetSharesTransformed
#| fig-cap: "Histogram of Target Share, Transformed."
#| fig-alt: "Histogram of Target Share, Transformed."

hist(
  log(player_stats_seasonal$target_share[which(player_stats_seasonal$position == "WR")] + 1),
  main = "Histogram of Target Share (Log Transformed)")
```

Now we can re-fit the model with the log-transformed variable.

```{r}
linearRegressionModel_logTargetShare <- lm(
  fantasyPoints ~ age + I(age^2) + height + I(height^2) + weight + I(weight^2) + I(log(target_share + 1)),
  data = player_stats_seasonal %>% filter(position %in% c("WR")),
  na.action = "na.exclude"
)

summary(linearRegressionModel_logTargetShare)
```

Target share shows a more linear association with fantasy points after log-transforming it (albeit still not perfect), as depicted in Figures [-@fig-marginalModelPlotsLogTransformed], [-@fig-addedVariablePlotsLogTransformed], [-@fig-componentPlusResidualPlotsLogTransformed], and [-@fig-residualPlotsLogTransformed].

```{r}
#| label: fig-marginalModelPlotsLogTransformed
#| fig-cap: "Marginal Model Plots After Log Transformation of Target Share."
#| fig-alt: "Marginal Model Plots After Log Transformation of Target Share."

car::marginalModelPlots(
  linearRegressionModel_logTargetShare,
  sd = TRUE,
  id = TRUE)
```

```{r}
#| label: fig-addedVariablePlotsLogTransformed
#| fig-cap: "Added-Variable Plots After Log Transformation of Target Share."
#| fig-alt: "Added-Variable Plots After Log Transformation of Target Share."

car::avPlots(
  linearRegressionModel_logTargetShare,
  id = TRUE)
```

```{r}
#| label: fig-componentPlusResidualPlotsLogTransformed
#| fig-cap: "Component-Plus-Residual Plots After Log Transformation of Target Share."
#| fig-alt: "Component-Plus-Residual Plots After Log Transformation of Target Share."

car::crPlots(
  linearRegressionModel_logTargetShare,
  id = TRUE)
```

When creating a residual plot, the `car` package [@Fox2019_packages; @R-car] also provides a test of the nonlinearity of each [predictor](#sec-correlationalStudy).

```{r}
#| label: fig-residualPlotsLogTransformed
#| fig-cap: "Residual Plots After Log Transformation of Target Share."
#| fig-alt: "Residual Plots After Log Transformation of Target Share."

car::residualPlots(
  linearRegressionModel_logTargetShare,
  id = TRUE)
```

#### Homoscedasticity {#sec-multipleRegressionExamplesAddressingAssumptionsHomoscedasticity}

To evaluate homoscedasticity, we can evaluate a residual plot (@fig-residualPlots) and spread-level plot (@fig-spreadLevelPlot) from the `car` package [@Fox2019_packages; @R-car].
In a residual plot, you want a constant spread of residuals versus fitted values—you do not want the residuals to show a fan or cone shape.

```{r}
#| label: fig-residualPlots
#| fig-cap: "Residual Plots."
#| fig-alt: "Residual Plots."

car::residualPlots(
  quadraticTermsRegressionModel,
  id = TRUE)
```

In a spread-level plot, you want a flat (zero) slope—you do not want a positive or negative slope.

```{r}
#| label: fig-spreadLevelPlot
#| fig-cap: "Spread-Level Plot."
#| fig-alt: "Spread-Level Plot."

car::spreadLevelPlot(
  quadraticTermsRegressionModel,
  id = TRUE)
```

In this example, the residuals appear to increase as a function of the fitted values.
To handle this, we may need to transform the [outcome variable](#sec-correlationalStudy) to be more normally distributed.

The histogram for raw fantasy points is in @fig-histogramFantasyPoints.

```{r}
#| label: fig-histogramFantasyPoints
#| fig-cap: "Histogram of Fantasy Points (Among Wide Receivers)."
#| fig-alt: "Histogram of Fantasy Points (Among Wide Receivers)."

hist(
  player_stats_seasonal$fantasyPoints[which(player_stats_seasonal$position == "WR")],
  main = "Histogram of Fantasy Points")
```

We can apply a Yeo-Johnson transformation to the [outcome variable](#sec-correlationalStudy) to generate a more normally distributed variable.
A Yeo-Johnson transformation estimates the optimal transformation to make the variable more normally distributed.
Let's use a Yeo-Johnson transformation of fantasy points:

```{r}
yjTransformed <- caret::preProcess(
  player_stats_seasonal["fantasyPoints"],
  method = c("YeoJohnson"))

yjTransformed

player_stats_seasonal$fantasyPoints_transformed <- predict(
  yjTransformed,
  newdata = player_stats_seasonal["fantasyPoints"])$fantasyPoints
```

The histogram of the transformed variable is in @fig-histogramFantasyPointsTransformed.

```{r}
#| label: fig-histogramFantasyPointsTransformed
#| fig-cap: "Histogram of Fantasy Points (Among Wide Receivers), Transformed."
#| fig-alt: "Histogram of Fantasy Points (Among Wide Receivers), Transformed."

hist(
  player_stats_seasonal$fantasyPoints_transformed[which(player_stats_seasonal$position == "WR")],
  main = "Histogram of Fantasy Points (Transformed)")
```

Now we can refit the model.

```{r}
linearRegressionModel_outcomeTransformed <- lm(
  fantasyPoints_transformed ~ age + height + weight + I(log(target_share + 1)),
  data = player_stats_seasonal %>% filter(position %in% c("WR")),
  na.action = "na.exclude"
)

summary(linearRegressionModel_outcomeTransformed)
```

The residual plot is in @fig-residualPlotsOutcomeTransformed.

```{r}
#| label: fig-residualPlotsOutcomeTransformed
#| fig-cap: "Residual Plots After Transformation of Fantasy Points."
#| fig-alt: "Residual Plots After Transformation of Fantasy Points."

car::residualPlots(
  linearRegressionModel_outcomeTransformed,
  id = TRUE)
```

The spread-level plot is in @fig-spreadLevelPlotOutcomeTransformed.

```{r}
#| label: fig-spreadLevelPlotOutcomeTransformed
#| fig-cap: "Spread-Level Plot After Transformation of Fantasy Points."
#| fig-alt: "Spread-Level Plot After Transformation of Fantasy Points."

car::spreadLevelPlot(
  linearRegressionModel_outcomeTransformed,
  id = TRUE)
```

The residuals show more constant variance after transforming the [outcome variable](#sec-correlationalStudy).

#### Uncorrelated Residuals {#sec-multipleRegressionExamplesAddressingAssumptionsUncorrelatedResiduals}

To determine if residuals are correlated given the nested structure of the data, we can examine the proportion of variance that is attributable to the particular player.
To do this, we can estimate the intraclass correlation coefficient (ICC) from a [mixed model](#sec-mixedModels) using the `performance` package [@Ludecke2021_packages; @R-performance].

```{r}
mixedModel <- lmer(
  fantasyPoints_transformed ~ 1 + (1 | player_id),
  data = player_stats_seasonal)

performance::icc(mixedModel)
```

The ICC indicates that over half of the variance is attribute to between-player variance, so it would be important to account for the player-specific variance using a [mixed model](#sec-mixedModels).
For simplicity, we focus on multiple regression models in this chapter; mixed models are described in @sec-mixedModels.

#### Normally Distributed Residuals {#sec-multipleRegressionExamplesAddressingAssumptionsNormallyDistributedResiduals}

We can examine whether residuals are normally distributed using quantile–quantile (QQ) plots and probability–probability (PP) plots, as in Figures [-@fig-qqPlot] and [-@fig-ppPlot].
If the residuals are normally distributed, they should stay close to the diagonal reference line.

```{r}
#| label: fig-qqPlot
#| fig-cap: "Residual Plots After Transformation of Fantasy Points."
#| fig-alt: "Residual Plots After Transformation of Fantasy Points."

car::qqPlot(
  linearRegressionModel_outcomeTransformed,
  main = "QQ Plot",
  id = TRUE)
```


```{r}
#| label: fig-ppPlot
#| fig-cap: "Residual Plots After Transformation of Fantasy Points."
#| fig-alt: "Residual Plots After Transformation of Fantasy Points."

petersenlab::ppPlot(
  linearRegressionModel_outcomeTransformed)
```

## Multicollinearity {#sec-multipleRegressionMulticollinearity}

*Multicollinearity* occurs when two or more [predictor variables](#sec-correlationalStudy) in a regression model are highly correlated.
The problem of having multiple [predictor variables](#sec-correlationalStudy) that are highly correlated is that it makes it challenging to estimate the regression coefficients accurately.

Multicollinearity in multiple regression is depicted conceptually in @fig-regression.

::: {#fig-regression}
![](images/multipleRegressionMulticollinearity.png){width=50% fig-alt="Conceptual Depiction of Multicollinearity in Multiple Regression. From @Petersen2024a and @PetersenPrinciplesPsychAssessment."}

Conceptual Depiction of Multicollinearity in Multiple Regression. From @Petersen2024a and @PetersenPrinciplesPsychAssessment.
:::

Consider the following example adapted from @PetersenPrinciplesPsychAssessment where you have two [predictor variables](#sec-correlationalStudy) and one [outcome variable](#sec-correlationalStudy), as shown in @tbl-regression3.

```{r}
#| echo: false

regression3 <- data.frame(
  "y" = c(9, 11, 17, 3, 21, 13),
  "x1" = c(2, 3, 4, 1, 5, 3.5),
  "x2" = c(4, 6, 8, 2, 10, 7))
```

```{r}
#| label: tbl-regression3
#| tbl-cap: "Example Data of Predictors (x1 and x2) and Outcome (y) Used for Regression Model."
#| echo: false

knitr::kable(
  regression3,
  col.names = c("y","x1","x2"),
  booktabs = TRUE)
```

The second [predictor variable](#sec-correlationalStudy) is not very good—it is exactly twice the value of the first [predictor variable](#sec-correlationalStudy); thus, the two [predictor variables](#sec-correlationalStudy) are perfectly correlated (i.e., $r = 1.0$).
This means that there are different prediction equation possibilities that are equally good—see Equations in @eq-multicollinearity:

$$
\begin{aligned}
  2x_2 &= y \\
  0x_1 + 2x_2 &= y \\
  4x_1 &= y \\
  4x_1 + 0x_2 &= y \\
  2x_1 + 1x_2 &= y \\
  5x_1 - 0.5x_2 &= y \\
  ...
&= y
\end{aligned}
$$ {#eq-multicollinearity}

Then, what are the regression coefficients?
We do not know what are the correct regression coefficients because each of the possibilities fits the data equally well.
Thus, when estimating the regression model, we could obtain arbitrary estimates of the regression coefficients with an enormous standard error around each estimate.
In general, multicollinearity increases the uncertainty (i.e., standard errors and confidence intervals) around the parameter estimates.
Any [predictor variables](#sec-correlationalStudy) that have a correlation above ~ $r = .30$ with each other could have an impact on the confidence interval of the regression coefficient.
As the correlations among the [predictor variables](#sec-correlationalStudy) increase, the chance of getting an arbitrary answer increases, sometimes called "bouncing betas."
So, it is important to examine a correlation matrix of the [predictor variables](#sec-correlationalStudy) before putting them in the same regression model.
You can also examine indices such as variance inflation factor (VIF), where a value greater than 5 or 10 indicates multicollinearity.

Here are the VIFs from our earlier model:

```{r}
car::vif(linearRegressionModel_outcomeTransformed)
```

To address multicollinearity, you can drop a redundant predictor or you can also use [principal component analysis](#sec-pca) or [factor analysis](#sec-factorAnalysis) of the [predictors](#sec-correlationalStudy) to reduce the [predictors](#sec-correlationalStudy) down to a smaller number of meaningful [predictors](#sec-correlationalStudy).
For a meaningful answer regarding [predictors](#sec-correlationalStudy) in a regression framework that is precise and confident, you need a low level of intercorrelation among [predictors](#sec-correlationalStudy), unless you have a very large sample size.
However, if you are merely interested in prediction—and are not interested in interpreting the regression coefficients of individual predictors—multicollinearity poses less of a problem.
For instance, [machine learning](#sec-machineLearning) cares more about achieving the greatest predictive accuracy possible and cares less about explaining which [predictors](#sec-correlationalStudy) are causally related to the [outcome](#sec-correlationalStudy).
So, multicollinearity is less of a concern for [machine learning](#sec-machineLearning) approaches.

## Handling of Missing Data {#sec-multipleRegressionMissingness}

An important consideration in multiple regression is how missing data are handled.
Multiple regression in `R` using the `lm()` function applies listwise deletion.
*Listwise deletion* removes any row (in the data file) from analysis that has a missing value on the [outcome variable](#sec-correlationalStudy) or any of the [predictor variables](#sec-correlationalStudy).
Removing all rows from analysis that have any missingness in the model variables can be a problem because missingness is often not completely at random—missingness often occurs systematically (i.e., for a reason).
For instance, participants may be less likely to have data for all variables if they are from a lower socioeconomic status background and do not have the time to participate in all study procedures.
Thus, applying listwise deletion, we might systematically exclude participants from lower socioeconomic status backgrounds (or other groups), which could lead to less generalizable inferences.

It is thus important to consider approaches to handle missingness.
Various approaches to handle missingness include pairwise deletion (aka available-case analysis), multiple imputation, and full information maximum likelihood (FIML).

### Pairwise Deletion {#sec-multipleRegressionPairwiseDeletion}

We can estimate a regression model that uses pairwise deletion using the `lavaan` package [@Rosseel2012_packages; @R-lavaan].

```{r}
player_stats_seasonal$target_share_log <- log(player_stats_seasonal$target_share + 1)

modelData <- player_stats_seasonal %>% 
  filter(position %in% c("WR")) %>% 
  select(fantasyPoints_transformed, age, height, weight, target_share_log)

numObs <- sum(complete.cases(modelData))
varMeans <- colMeans(modelData, na.rm = TRUE)
varCovariances <- cov(modelData, use = "pairwise.complete.obs")

pairwiseRegression_syntax <- '
  fantasyPoints_transformed ~ age + height + weight + target_share_log
  fantasyPoints_transformed ~~ fantasyPoints_transformed
  fantasyPoints_transformed ~ 1
'

pairwiseRegression_fit <- lavaan::lavaan(
  pairwiseRegression_syntax,
  sample.mean = varMeans,
  sample.cov = varCovariances,
  sample.nobs = numObs
)

summary(
  pairwiseRegression_fit,
  standardized = TRUE,
  rsquare = TRUE)
```

### Multiple Imputation {#sec-multipleRegressionMultipleImputation}

We can multiply impute data using the `mice` package [@vanBuuren2011_packages; @R-mice].

```{r}
numImputations <- 5

dataToImpute <- player_stats_seasonal %>% 
  filter(position %in% c("WR")) %>% 
  select(player_id, position, where(is.numeric)) %>% 
  select(
    player_id:games, carries:wopr, fantasy_points, fantasy_points_ppr,
    rush_40_yds, rec_40_yds, fumbles, two_pts, return_yds,
    rush_100_yds:draftround, height:target_share_log) %>% 
  select(-c(fantasy_points_ppr, ageCentered20, target_share_log)) # drop collinear variables

predictors <- c("targets","receiving_yards","receiving_air_yards","receiving_yards_after_catch","receiving_first_downs","racr")

dataToImpute$player_id_integer <- as.integer(as.factor(dataToImpute$player_id))

varsToImpute <- c("age","height","weight","target_share")
Y <- varsToImpute
```

Now, let's specify the imputation method—we use the two-level predictive mean matching (`2l.pmm`) method from the `miceadds` package [@R-miceadds] to account for the nonindependent data (owing to multiple seasons per player):

```{r}
meth <- mice::make.method(dataToImpute)
meth[1:length(meth)] <- ""
meth[Y] <- "2l.pmm" # specify the imputation method here; this can differ by outcome variable
```

Now, let's specify the prediction matrix.
A predictor matrix is a matrix of values, where:

- columns with non-zero values are [predictors](#sec-correlationalStudy) of the variable specified in the given row
- the diagonal of the predictor matrix should be zero because a variable cannot predict itself

The values are:

- NOT a predictor of the outcome: `0`
- cluster variable: `-2`
- fixed effect of predictor: `1`
- fixed effect and random effect of predictor: `2`
- include cluster mean of predictor in addition to fixed effect of predictor: `3`
- include cluster mean of predictor in addition to fixed effect and random effect of predictor: `4`

```{r}
pred <- mice::make.predictorMatrix(dataToImpute)
pred[1:nrow(pred), 1:ncol(pred)] <- 0
pred[Y, "player_id_integer"] <- (-2) # cluster variable
pred[Y, predictors] <- 1 # fixed effect predictors
pred[Y, "age"] <- 2 # random effect predictor
pred[Y, Y] <- 1 # fixed effect predictor

diag(pred) <- 0
```

Now, let's run the imputation:

```{r}
#| output: false

imp <- mice::mice(
  as.data.frame(dataToImpute),
  method = meth,
  predictorMatrix = pred,
  m = numImputations,
  maxit = 5, # generally use 100 maximum iterations; this example uses 5 for speed
  seed = 52242)
```

Below are some imputation diagnostics.
Trace plots are in @fig-miTracePlots.

```{r}
#| label: fig-miTracePlots
#| fig-cap: "Trace plots from multiple imputation."
#| fig-alt: "Trace plots from multiple imputation."

plot(imp, c("target_share"))
```

A density plot is in @fig-miDensityPlot.

```{r}
#| label: fig-miDensityPlot
#| fig-cap: "Density plot from multiple imputation."
#| fig-alt: "Density plot from multiple imputation."

densityplot(imp, ~ target_share)
```

The imputated data does not match well the distribution of the observed data.
Thus, it may be necessary to select a different imputation method for more accurate imputation.

Now, let's do some post-processing:

```{r}
imp_long <- mice::complete(
  imp,
  action = "long",
  include = TRUE)

imp_long$target_share_log <- log(imp_long$target_share + 1)

imp_long$fantasyPoints_transformed <- predict(
  yjTransformed,
  newdata = imp_long["fantasyPoints"])$fantasyPoints

imp_mids <- mice::as.mids(imp_long)
```

Now let's estimate multiple regression with the multiply imputed data:

```{r}
imp_regression <- with(
  imp_mids,
  lm(
    fantasyPoints_transformed ~ age + height + weight + target_share_log)
  )

summary(mice::pool(imp_regression))
```

### Full Information Maximum Likelihood {#sec-multipleRegressionFIML}

We can estimate a regression model that uses full information maximum likelihood using the `lavaan` package [@Rosseel2012_packages; @R-lavaan].

```{r}
fimlRegression_syntax <- '
  fantasyPoints_transformed ~ age + height + weight + target_share_log
  fantasyPoints_transformed ~~ fantasyPoints_transformed
  fantasyPoints_transformed ~ 1
'

fimlRegression_fit <- lavaan::sem(
  fimlRegression_syntax,
  data = player_stats_seasonal %>% filter(position %in% c("WR")),
  missing = "ML",
  fixed.x = FALSE
)

summary(
  fimlRegression_fit,
  standardized = TRUE,
  rsquare = TRUE)
```

## Addressing Non-Independence of Observations {#sec-multipleRegressionNonIndependence}

Please note that the $p$-value for regression coefficients assumes that the observations are independent—in particular, that the residuals are not correlated.
However, the observations are not independent in the `player_stats_seasonal` dataframe used above, because the same player has multiple rows—one row corresponding to each season they played.
This non-independence violates the traditional assumptions of the significance of regression coefficients.
We could address this assumption by analyzing only one season from each player or by estimating the significance of the regression coefficients using cluster-robust standard errors.
For simplicity in the models above, we present results above from the whole dataframe.
In @sec-mixedModels, we discuss [mixed model](#sec-mixedModels) approaches that handle repeated measures and other data that violate assumptions of non-independence.
Below, we demonstrate how to account for non-independence of observations using cluster-robust standard errors with the `rms` package [@R-rms].

```{r}
player_stats_seasonal_subset <- player_stats_seasonal %>% 
  filter(!is.na(player_id)) %>% 
  filter(position %in% c("WR"))

regressionWithClusterVariable <- rms::robcov(rms::ols(
  fantasyPoints_transformed ~ age + height + weight + I(log(target_share + 1)),
  data = player_stats_seasonal_subset,
  x = TRUE,
  y = TRUE),
  cluster = player_stats_seasonal_subset$player_id) #account for nested data within player

regressionWithClusterVariable
performance::r2(regressionWithClusterVariable)
```

## Impact of Outliers {#sec-multipleRegressionOutliers}

[As with correlation](#sec-correlationOutliers), multiple regression can be strongly impacted by outliers.

### Robust Regression {#sec-multipleRegressionRobustRegression}

To address outliers, there are various approaches to robust regression.
One approach is to use an MM-type estimator, such as is used in the `lmrob()` and `glmrob()` functions of the `robustbase` package [@R-robustbase; @Todorov2009_packages].

```{r}
robustRegression <- robustbase::lmrob(
  fantasyPoints_transformed ~ age + height + weight + I(log(target_share + 1)),
  data = player_stats_seasonal %>% filter(position %in% c("WR"))
)

summary(robustRegression)
```

Another approach to handling outliers is to use boostrapping, which involves fitting models to various bootstrap resamples of the data.
Bootstrap samples are datasets generated by sampling repeatedly with replacement.

We set up the bootstrap folds using the `bootstraps()` function of the `rsample` package [@R-rsample].

```{r}
set.seed(52242)
bootstrapSamples <- 2000

# Create bootstrap resamples (with apparent = TRUE)
boots <- rsample::bootstraps(
  data = player_stats_seasonal %>% filter(position %in% c("WR")),
  times = bootstrapSamples,
  apparent = TRUE
)

# Define recipe
rec <- recipes::recipe(
  fantasyPoints_transformed ~ age + height + weight + target_share,
  data = player_stats_seasonal %>% filter(position %in% c("WR"))
) %>%
  recipes::step_log(target_share, offset = 1) # replace I(log(target_share + 1))

# Define model spec and workflow
lm_spec <- parsnip::linear_reg() %>%
  parsnip::set_engine("lm") %>%
  parsnip::set_mode("regression")

lm_workflow <- workflows::workflow() %>%
  workflows::add_recipe(rec) %>%
  workflows::add_model(lm_spec)

# Function for fitting the models on the bootstrap samples
fit_lm <- function(split, ...) {
  analysis_data <- rsample::analysis(split)
  fit <- workflows::fit(lm_workflow, data = analysis_data)
  broom::tidy(fit)
}

# Fit bootstrap models and save results
boot_models <- boots %>%
  mutate(coef_info = purrr::map(splits, fit_lm))

# Extract bootstrapped coefficient estimates
boot_coefs <- boot_models %>%
  tidyr::unnest(coef_info)

# Percentile confidence intervals
percentile_intervals <- rsample::int_pctl(
  .data = boot_models,
  statistics = coef_info)

# Bias-corrected and accelerated confidence intervals
bca_intervals <- rsample::int_bca(
  .data = boot_models,
  statistics = coef_info,
  .fn = fit_lm
)

# View confidence intervals
percentile_intervals
bca_intervals
```

The distributions of the regression coefficients across boostraps are depicted in @fig-bootstrapRegressionCoefficients.

```{r}
#| label: fig-bootstrapRegressionCoefficients
#| fig-cap: "Histogram of Parameter Estimates Across Bootstraps."
#| fig-alt: "Histogram of Parameter Estimates Across Bootstraps."

ggplot(
  data = boot_coefs,
  aes(x = estimate)) +
  geom_histogram(
    fill = "gray80",
    color = "black") +
  facet_wrap(
    ~ term,
    scales = "free") +
  geom_vline(
    data = percentile_intervals,
    aes(
      xintercept = .lower),
    col = "blue",
    linetype = "dashed") +
  geom_vline(
    data = percentile_intervals,
    aes(
      xintercept = .upper),
    col = "blue",
    linetype = "dashed") +
  labs(
    title = "Bootstrap Distributions of Coefficients",
    x = "Coefficient Estimate",
    y = "Count") +
  theme_classic()
```

## Moderated Multiple Regression {#sec-moderatedMultipleRegression}

When examining moderation in multiple regression, several steps are important:

- When computing the interaction term, first mean-center the [predictor variables](#sec-correlationalStudy).
Calculate the interaction term as the multiplication of the mean-centered [predictor variables](#sec-correlationalStudy).
Mean-centering the [predictor variables](#sec-correlationalStudy) when computing the interaction term is important for addressing issues regarding [multicollinearity](#sec-multipleRegressionMulticollinearity) [@Iacobucci2016].
- When including an interaction term in the model, make sure also to include the main effects.

First, we mean-center the [predictors](#sec-correlationalStudy).
In this case, we center the [predictors](#sec-correlationalStudy) around the mean of height and weight for Wide Receivers:

```{r}
player_stats_seasonal$height_centered <- player_stats_seasonal$height - mean(player_stats_seasonal$height[which(player_stats_seasonal$position == "WR")], na.rm = TRUE)
player_stats_seasonal$weight_centered <- player_stats_seasonal$weight - mean(player_stats_seasonal$weight[which(player_stats_seasonal$position == "WR")], na.rm = TRUE)
```

Then, we compute the interaction term as the multiplication of the two centered [predictors](#sec-correlationalStudy):

```{r}
player_stats_seasonal$heightXweight <- player_stats_seasonal$height_centered * player_stats_seasonal$weight_centered
```

Then, we fit the moderated multiple regression model:

```{r}
moderationModel <- lm(
  fantasyPoints_transformed ~ height_centered + weight_centered + height_centered:weight_centered,
  data = player_stats_seasonal %>% filter(position %in% c("WR")),
  na.action = "na.exclude"
)

summary(moderationModel)
```

This model is equivalent to the model that includes the interaction term explicitly:

```{r}
#| eval: false

moderationModel <- lm(
  fantasyPoints_transformed ~ height_centered + weight_centered + heightXweight,
  data = player_stats_seasonal %>% filter(position %in% c("WR")),
  na.action = "na.exclude"
)

summary(moderationModel)
```

Now, we can visualize the interaction to understand it.
We create an interaction plot (@fig-interactionPlot) and Johnson-Neyman plot (@fig-johnsonNeymanPlot) using the `interactions` package [@R-interactions].

```{r}
#| label: fig-interactionPlot
#| fig-cap: "Interaction Plot from Moderated Multiple Regression."
#| fig-alt: "Interaction Plot from Moderated Multiple Regression."

interactions::interact_plot(
  moderationModel,
  pred = height_centered,
  modx = weight_centered)
```

```{r}
#| label: fig-johnsonNeymanPlot
#| fig-cap: "Johnson-Neyman Plot from Moderated Multiple Regression."
#| fig-alt: "Johnson-Neyman Plot from Moderated Multiple Regression."

interactions::johnson_neyman(
  moderationModel,
  pred = height_centered,
  modx = weight_centered,
  alpha = .05)
```

Here is a simple slopes analysis:

```{r}
interactions::sim_slopes(
  moderationModel,
  pred = height_centered,
  modx = weight_centered,
  johnson_neyman = FALSE)
```

## Mediation {#sec-multipleRegressionMediation}

A mediation model takes the following general form in the `lavaan` package [@Rosseel2012_packages; @R-lavaan].

```{r}
#| eval: false

mediationModel <- '
  # direct effect (cPrime)
  Y ~ direct*X
  
  # mediator
  M ~ a*X
  Y ~ b*M
  
  # indirect effect = a*b
  indirect := a*b
  
  # total effect (c)
  total := abs(direct) + abs(indirect)
'
```

Let's substitute in our [predictor](#sec-correlationalStudy), [outcome](#sec-correlationalStudy), and hypothesized [mediator](#sec-mediation).
In this case, we predict that receiving touchdowns partially accounts for the association between Wide Receiver's target share and their fantasy points.
This is a silly example because fantasy points are derived, in part, from touchdowns, so of course touchdowns will partially account for almost any effect on Wide Receivers' fantasy points.
This example is merely for demonstrating the process of developing and examining a mediation model.

```{r}
mediationModel <- '
  # direct effect (cPrime)
  fantasyPoints_transformed ~ direct*target_share
  
  # mediator
  receiving_tds ~ a*target_share
  fantasyPoints_transformed ~ b*receiving_tds
  
  # indirect effect = a*b
  indirect := a*b
  
  # total effect (c)
  total := abs(direct) + abs(indirect)
'
```

To get a robust estimate of the indirect effect, we obtain bootstrapped estimates from 1,000 bootstrap draws.
Typically, we would obtain bootstrapped estimates from 10,000 bootstrap draws, but this example uses only 1,000 bootstrap draws for a shorter runtime.

```{r}
mediationFit <- lavaan::sem(
  mediationModel,
  data = player_stats_seasonal %>% filter(position %in% c("WR")),
  se = "bootstrap",
  bootstrap = 1000, # generally use 10,000 bootstrap draws; this example uses 1,000 for speed
  parallel = "multicore", # parallelization for speed: use "multicore" for Mac/Linux; "snow" for PC
  iseed = 52242, # for reproducibility
  missing = "ML",
  estimator = "ML",
  fixed.x = FALSE)
```

Here are the model results:

```{r}
summary(
  mediationFit,
  fit.measures = TRUE,
  standardized = TRUE,
  rsquare = TRUE)
```

We can also estimate a model with multiple hypothesized [mediators](#sec-mediations):

```{r}
multipleMediatorModel <- '
  # direct effect (cPrime)
  fantasyPoints_transformed ~ direct*target_share
  
  # mediator
  receiving_tds ~ a1*target_share
  receiving_yards ~ a2*target_share
  
  fantasyPoints_transformed ~ b1*receiving_tds + b2*receiving_yards
  
  # indirect effect = a*b
  indirect1 := a1*b1
  indirect2 := a2*b2
  indirectTotal := indirect1 + indirect2
  
  # total effect (c)
  total := abs(direct) + abs(indirectTotal)
'
```

```{r}
multipleMediatorFit <- lavaan::sem(
  multipleMediatorModel,
  data = player_stats_seasonal %>% filter(position %in% c("WR")),
  se = "bootstrap",
  bootstrap = 1000, # generally use 10,000 bootstrap draws; this example uses 1,000 for speed
  parallel = "multicore", # parallelization for speed: use "multicore" for Mac/Linux; "snow" for PC
  iseed = 52242, # for reproducibility
  missing = "ML",
  estimator = "ML",
  fixed.x = FALSE)
```

Here are the model results:

```{r}
summary(
  multipleMediatorFit,
  fit.measures = TRUE,
  standardized = TRUE,
  rsquare = TRUE)
```

## Bayesian Multiple Regression {#sec-multipleRegressionBayesian}

```{r}
#| output: false

bayesianMultipleRegressionModel <- brm(
  formula = fantasyPoints_transformed ~ age + height + weight + I(log(target_share + 1)),
  data = player_stats_seasonal %>% filter(position %in% c("WR")),
  family = gaussian()
)
```

```{r}
summary(bayesianMultipleRegressionModel)
performance::r2(bayesianMultipleRegressionModel)
```

## Conclusion {#sec-multipleRegressionConclusion}

Multiple regression allows examining the association between multiple [predictor variables](#sec-correlationalStudy) and one [outcome variable](#sec-correlationalStudy).
Inclusion of multiple [predictors](#sec-correlationalStudy) in the model allows for potentially greater predictive accuracy and identification of the extent to which each variable uniquely contributes to the [outcome variable](#sec-correlationalStudy).
As with [correlation](#sec-correlation), an association does not imply causation.
However, identifying associations is important because associations are a necessary (but insufficient) condition for causality.
When developing a multiple regression model, there are various [assumptions](#sec-assumptionsRegression) that are important to evaluate.
In addition, it is important to pay attention for potential [multicollinearity](#sec-multipleRegressionMulticollinearity)—it may become difficult to detect a given [predictor variable](#sec-correlationalStudy) as [statistically significant](#sec-statisticalSignificance) due to the greater uncertainty around the parameter estimates.

::: {.content-visible when-format="html"}

## Session Info {#sec-multipleRegressionSessionInfo}

```{r}
sessionInfo()
```

:::
