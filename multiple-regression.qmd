# Multiple Regression {#sec-multipleRegression}

## Getting Started {#sec-multipleRegressionGettingStarted}

### Load Packages {#sec-multipleRegressionLoadPackages}

```{r}

```

## Overview of Multiple Regression {#sec-multipleRegressionOverview}

Multiple regression examines the association between multiple predictor variables and one outcome variable.
It allows obtaining a more accurate estimate of the unique contribution of a given predictor, by controlling for other variables ([covariates](#sec-covariates)).

Regression with a single predictor takes the form in @eq-regression.
A regression line is depicted in @fig-regression.
Multiple regression (i.e., regression with multiple predictors) takes the form in @eq-multipleRegression.

## Components {#sec-multipleRegressionComponents}

- $B$ = unstandardized coefficient: direction and magnitude of the estimate (original scale)
- $\beta$ = standardized coefficient: direction and magnitude of the estimate (standard deviation scale)
- $SE$ = standard error: uncertainty of unstandardized estimate

## Coefficient of Determination ($R^2$) {#sec-multipleRegressionRSquared}

::: {#fig-regression}
![](images/multipleRegressionRSquared.png)

Conceptual Depiction of Proportion of Variance Explained ($R^2$) in an Outcome Variable ($Y$) by Multiple Predictors ($X1$ and $X2$) in Multiple Regression. The size of each circle represents the variable's variance. The proportion of variance in $Y$ that is explained by the predictors is depicted by the areas in orange. The dark orange space ($G$) is where multiple predictors explain overlapping variance in the outcome. Overlapping variance that is explained in the outcome ($G$) will not be recovered in the regression coefficients when both predictors are included in the regression model. From @Petersen2024a and @PetersenPrinciplesPsychAssessment.
:::

## Covariates {#sec-covariates}

Covariates are variables that you include in the statistical model to try to control for them so you can better isolate the unique contribution of the predictor variable(s) in relation to the outcome variable.
Use of covariates examines the association between the predictor variable and the outcome variable when holding people's level constant on the covariates.
Inclusion of confounds as covariates allows potentially gaining a more accurate estimate of the causal effect of the predictor variable on the outcome variable.
Ideally, you want to include any and all confounds as covariates.
As described in @sec-correlationCausation, confounds are third variables that influence both the predictor variable and the outcome variable and explain their association.
Covariates are potentially (but not necessarily) confounds.
For instance, you might include the player's age as a covariate in a model that examines whether a player's 40-yard dash time at the NFL Combine predicts their fantasy points in their rookie year, but it may not be a confound.

## Multicollinearity {#sec-multipleRegressionMulticollinearity}

::: {#fig-regression}
![](images/multipleRegressionMulticollinearity.png)

Conceptual Depiction of Multicollinearity in Multiple Regression. From @Petersen2024a and @PetersenPrinciplesPsychAssessment.
:::
