# Heuristics and Cognitive Biases in Prediction {#sec-cognitiveBias}

## Getting Started {#sec-cognitiveBiasGettingStarted}

### Load Packages {#sec-cognitiveBiasLoadPackages}

```{r}

```

## Overview {#sec-cognitiveBiasOverview}

When considering judgment and prediction, it is important to consider psychological concepts, including heuristics and cognitive biases.
In the modern world of big data, research and society need people who know how to make sense of the information around us.
Given humans' cognitive biases, it is valuable to leverage more objective approaches than relying on our "gut" and intutition.
Statistical approaches can be a more objective way to identify systematic patterns.

Statistical analysis—and science more generally—is a process to the pursuit of knowledge.
An *epistemology* is an approach to knowledge.
Science is perhaps the best approach (epistemology) that society has to approximate truth.
Unlike other approaches to knowledge, science relies on empirical evidence and does not give undue weight to anecdotal evidence, intuition, tradition, or authority.

Per @PetersenPrinciplesPsychAssessment, here are the characteristics of science that distinguish it from pseudoscience:

> 1. Risky hypotheses are posed that are falsifiable.
> The hypotheses can be shown to be wrong.
> 1. Findings can be replicated independently by different research groups and different methods.
> Evidence converges across studies and methods.
> 1. Potential alternative explanations for findings are specified and examined empirically (with data).
> 1. Steps are taken to guard against the undue influence of personal beliefs and biases.
> 1. The strength of claims reflects the strength of evidence.
> Findings and the ability to make judgments or predictions are not overstated.
> For instance, it is important to present the degree of uncertainty from assessments with error bars or confidence intervals.
> 1. Scientifically supported measurement strategies are used based on their psychometrics, including [reliability](#sec-reliability) and [validity](#sec-validity).

Nevertheless, statistical analysis is not purely objective and is not a panacea.
Science is a human enterprise—it is performed by humans each of whom has their own biases.
For instance, cognitive biases can influence how people interpret statistics.
As a result, the findings from any given study may be incorrect.
Thus, it would be imprudent to make decisions based solely on the results of one study.
That is why we wait for findings to be independently replicated by different groups of researchers using different methods.

If a research team publishes flashy new and exciting findings, other researchers have an incentive to disprove the prior findings.
Thus, we have more confidence if findings stand up to scrutiny from independent groups of researchers.
We also draw upon meta-analyses—studies of many studies, to summarize the results of many studies and not just the findings from any single study that may not replicate.
In this way, we can identify which findings are robust and most likely true versus the findings that fail to replicate.
Thus, despite its flaws like any other human enterprise, science is a self-correcting process in which the long arc bends toward truth.

In our everyday lives, humans are presented with overwhelming amounts of information.
Because human minds cannot parse every piece of information equally, we tend to take mental shortcuts, called *heuristics*.
These mental shortcuts can be helpful.
They can help us make quick judgments to stay alive or to make complex decisions in the face of uncertainty.
However, these mental shortcuts can also lead us astray and make systematic errors in our judgments and predictions.
*Cognitive biases* are systematic errors in thinking.

## Examples of Heuristics {#sec-heuristics}

## Examples of Cognitive Biases {#sec-cognitiveBiases}

## Conclusion {#sec-cognitiveBiasConclusion}

::: {.content-visible when-format="html"}

## Session Info {#sec-cognitiveBiasSessionInfo}

```{r}
sessionInfo()
```

:::
