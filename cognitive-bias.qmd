# Heuristics and Cognitive Biases in Prediction {#sec-cognitiveBias}

## Getting Started {#sec-cognitiveBiasGettingStarted}

### Load Packages {#sec-cognitiveBiasLoadPackages}

```{r}

```

## Overview {#sec-cognitiveBiasOverview}

When considering judgment and prediction, it is important to consider psychological concepts, including heuristics and cognitive biases.
In the modern world of big data, research and society need people who know how to make sense of the information around us.
Given humans' cognitive biases, it is valuable to leverage more objective approaches than relying on our "gut" and intutition.
Statistical approaches can be a more objective way to identify systematic patterns.

Statistical analysis—and science more generally—is a process to the pursuit of knowledge.
An *epistemology* is an approach to knowledge.
Science is perhaps the best approach (epistemology) that society has to approximate truth.
Unlike other approaches to knowledge, science relies on empirical evidence and does not give undue weight to anecdotal evidence, intuition, tradition, or authority.
Nevertheless, statistical analysis is not purely objective and is not a panacea.
Science is a human enterprise—it is performed by humans each of whom has their own biases.
For instance, cognitive biases can influence how people interpret statistics.
As a result, the findings from any given study may be incorrect.
Thus, it would be imprudent to make decisions based solely on the results of one study.
That is why we wait for findings to be independently replicated by different groups of researchers using different methods.

If a research team publishes flashy new and exciting findings, other researchers have an incentive to disprove the prior findings.
Thus, we have more confidence if findings stand up to scrutiny from independent groups of researchers.
We also draw upon meta-analyses—studies of many studies, to summarize the results of many studies and not just the findings from any single study that may not replicate.
In this way, we can identify which findings are robust and most likely true versus the findings that fail to replicate.
Thus, despite its flaws like any other human enterprise, science is a self-correcting process in which the long arc bends toward truth.

In our everyday lives, humans are presented with overwhelming amounts of information.
Because human minds cannot parse every piece of information equally, we tend to take mental shortcuts, called *heuristics*.
These mental shortcuts can be helpful.
They can help us make quick judgments to stay alive or to make complex decisions in the face of uncertainty.
However, these mental shortcuts can also lead us astray and make systematic errors in our judgments and predictions.
*Cognitive biases* are systematic errors in thinking.

## Examples of Heuristics {#sec-heuristics}

## Examples of Cognitive Biases {#sec-cognitiveBiases}

## Conclusion {#sec-cognitiveBiasConclusion}

::: {.content-visible when-format="html"}

## Session Info {#sec-cognitiveBiasSessionInfo}

```{r}
sessionInfo()
```

:::
