# Heuristics and Cognitive Biases in Prediction {#sec-cognitiveBias}

## Getting Started {#sec-cognitiveBiasGettingStarted}

### Load Packages {#sec-cognitiveBiasLoadPackages}

```{r}
library("tidyverse")
```

## Overview {#sec-cognitiveBiasOverview}

When considering judgment and prediction, it is important to consider psychological concepts, including heuristics and cognitive biases.
In the modern world of big data, research and society need people who know how to make sense of the information around us.
Given humans' cognitive biases, it is valuable to leverage more objective approaches than relying on our "gut" and intutition.
Statistical approaches can be a more objective way to identify systematic patterns.

Statistical analysis—and science more generally—is a process to the pursuit of knowledge.
An *epistemology* is an approach to knowledge.
Science is perhaps the best approach (epistemology) that society has to approximate truth.
Unlike other approaches to knowledge, science relies on empirical evidence and does not give undue weight to anecdotal evidence, intuition, tradition, or authority.

Per @PetersenPrinciplesPsychAssessment, here are the characteristics of science that distinguish it from pseudoscience:

> 1. Risky hypotheses are posed that are falsifiable.
> The hypotheses can be shown to be wrong.
> 1. Findings can be replicated independently by different research groups and different methods.
> Evidence converges across studies and methods.
> 1. Potential alternative explanations for findings are specified and examined empirically (with data).
> 1. Steps are taken to guard against the undue influence of personal beliefs and biases.
> 1. The strength of claims reflects the strength of evidence.
> Findings and the ability to make judgments or predictions are not overstated.
> For instance, it is important to present the degree of uncertainty from assessments with error bars or confidence intervals.
> 1. Scientifically supported measurement strategies are used based on their psychometrics, including [reliability](#sec-reliability) and [validity](#sec-validity).

Nevertheless, statistical analysis is not purely objective and is not a panacea.
Science is a human enterprise—it is performed by humans each of whom has their own biases.
For instance, cognitive biases can influence how people interpret statistics.
As a result, the findings from any given study may be incorrect.
Thus, it would be imprudent to make decisions based solely on the results of one study.
That is why we wait for findings to be independently replicated by different groups of researchers using different methods.

If a research team publishes flashy new and exciting findings, other researchers have an incentive to disprove the prior findings.
Thus, we have more confidence if findings stand up to scrutiny from independent groups of researchers.
We also draw upon meta-analyses—studies of many studies, to summarize the results of many studies and not just the findings from any single study that may not replicate.
In this way, we can identify which findings are robust and most likely true versus the findings that fail to replicate.
Thus, despite its flaws like any other human enterprise, science is a self-correcting process in which the long arc bends toward truth.

In our everyday lives, humans are presented with overwhelming amounts of information.
Because human minds cannot parse every piece of information equally, we tend to take mental shortcuts, called *heuristics*.
These mental shortcuts can be helpful.
They reduce our mental load and can help us make quick judgments to stay alive or to make complex decisions in the face of uncertainty.
However, these mental shortcuts can also lead us astray and to make systematic errors in our judgments and predictions.
*Cognitive biases* are systematic errors in thinking.
*Fallacies* are forms of flawed reasoning.

## Examples of Heuristics {#sec-heuristics}

As described [above](#sec-cognitiveBiasOverview), heuristics are mental shortcuts that people use to handle the overwhelming amount of information to process.
Three important heuristics used in judgment and prediction in the face of uncertainty include [@Tversky1974]:

- availability heuristic
- representativeness heuristic
- anchoring and adjustment heuristic

### Availability Heuristic {#sec-heuristicsAvailability}

The *availability heuristic* refers to the tendency for a person's judgments or predictions about the frequency or probability of something to be made based on how readily instances can be brought to mind.
For instance, when making fantasy predictions about a player, more recent big performance games may more easily come to mind compared to lower-scoring games and games that occurred longer ago.
Thus, a manager may be more inclined to pick players to start who had more recent, stronger performances rather than players who have higher long-term averages.

### Representativeness Heuristic {#sec-heuristicsRepresentativeness}

The *representativess heuristic* refers to the tendency for a person's judgments or predictions about individuals to be made based on how similar the individual is to the person's existing mental prototypes.
For instance, when coming out of college, Tight End Kyle Pitts [drew comparisons](https://247sports.com/article/kyle-pitts-lebron-james-2021-nfl-draft-florida-gators-football-163882176) to the "LeBron James" of Tight Ends (archived at <https://perma.cc/JQB5-XPVL>).
The idea that his athletic profile leads him to be similar to the prototype of LeBron James may have led him to be too highly drafted by fantasy managers in his first seasons.

::: {.content-visible when-format="html:js"}

Here is a video of Kyle Pitts drawing comparisons to the LeBron James of Tight Ends:

![Video of Kyle Pitts drawing comparisons to the LeBron James of Tight Ends. From: <https://x.com/GetUpESPN/status/1380165126108672001> (archived at <https://perma.cc/JW8E-KV2C>)](images/kylePitts.mp4){width=100%}

:::

The representativeness heuristic has been observed in gambling markets for predicting team wins in the National Football League (NFL) [@Woodland2015] and in decision making in fantasy soccer [@Kotrba2020].

### Anchoring and Adjustment Heuristic {#sec-heuristicsAnchoringAdjustment}

The *anchoring and adjustment heuristic* refers to the tendency for a person's judgments or predictions to be made with a reference point—an anchor—as a starting point from which they adjust their estimates upward or downward.
The anchor is often inaccurate and given too much weight in the person's calculation, and too little adjustment is made to the anchor.
For instance, a manager is trying to predict how many fantasy points a top Running Back may score.
The player scored 300 fantasy points last season, but the team added a stronger backup Running Back and changed the Offensive Coordinator to be a more pass-heavy offense.
The manager may use 300 fantasy points as an anchor (based on the player's performance last season), and may adjust downward 15 points to account for the offseason changes.
However, it is possible that this downward adjustment is insufficient to account not only for the offseasons changes but also for potential [regression effects](#sec-fallaciesRegression).
[Regression effects](#sec-fallaciesRegression) are discussed further in @sec-fallaciesRegression.

## Examples of Cognitive Biases {#sec-cognitiveBiases}

As described [above](#sec-cognitiveBiasOverview), cognitive biases are systematic errors in thinking.
Cognitive biases are often due to the use of [heuristics](#sec-heuristics).
Examples of cognitive biases that result from one or more of these heuristics include:

- overconfidence bias
- confirmation bias
- recency bias
- hindsight bias
- loss aversion bias
- endowment bias
- bandwagon effect bias
- Dunning–Kruger effect bias

### Overconfidence Bias {#sec-cognitiveBiasesOverconfidence}

In general, people tend to be overconfident in their judgments and predictions.
*Overconfidence bias* is the tendency for a person to have greater confidence in their abilities (including judgments and predictions) than is objectively warranted.
There are three general ways that overconfidence has been identified [@Moore2008]:

1. *overestimation* of one's actual performance
1. *overplacement* of one's performance relative to others
1. *overprecision* in one's beliefs/jugments/predictions

*Overestimation* involves believing that one will perform better than one actually performs.
Overestimation can be identified with a [calibration plot](#sec-calibration) of the predicted performance versus actual performance, where the person's predicted performance is systematically higher (in at least some cases) than their actual performance.
Overestimation corresponds to the "[overprediction](#sec-calibration)" form of [miscalibration](#sec-calibration).

*Overplacement* involves believing that one is better than others or will perform better than others, even when they do not.
For instance, it is a common finding that more than half of people believe they are "above average" (i.e., above the median), even though that is statistically impossible.
This calls to mind the fictitious Lake Wobegon in the radio show *A Praririe Home Companion*, "where all the women are strong, all the men are good-looking, and all the children are above average."

*Overprecision* involves expressing excessive certainty regarding the accuracy of one's beliefs/judgments/predictions.
For instance, if when a given weather forecaster says it will rain 80% of the time, it actually rains 30% of the time, the weather forecaster's predictions are overprecise.
Likewise, if the weather forecast says it will rain 10% of the time and it actually rains 30% of the time, the predictions are also overprecise because the forecaster is expressing stronger confidence than is warranted that it will not rain.
Overprecision can be identified with a [calibration plot](#sec-calibration) of the predicted probabilities versus the actual probabilities.
Overprecision corresponds to the "[overextremity](#sec-calibration)" form of [miscalibration](#sec-calibration).

A fantasy manager may be even more likely to exhibit overconfidence if they previously performed well or won their league, for which luck and random chance plays an important role.
Indeed, it is estimated that nearly half (~45%) of the variability in fantasy football performance is estimated to be luck [and around 55% due to skill; @Getty2018].
A manager who won their league in the prior season may believe they will perform better than they actually will (overestimation), will perform better than average (overplacement), and may hold excessive confidence regarding the accuracy of their predictions about which players will perform well or poorly (overprecision).
These various types of overconfidence may lead them to draft high-risk players based on gut feeling, neglecting statistical analysis and expert consensus.

Players' performance in fantasy football, and human behavior more generally, is complex and multiply determined (i.e., is influenced by many factors).
Despite the bluster of so-called experts who pretend to know more than they can know, no one can consistently and accurately predict how all players will perform.
Remain humble in your predictions; do not be more confident than is warranted.
If you approach the task of prediction with humility, you may be more able to be flexible and more willing to consider other players who you can draft for good value.

### Confirmation Bias {#sec-cognitiveBiasesConfirmation}

*Confirmation bias* is the tendency for people to search for, interpret, and remember information that confirms one's beliefs, as opposed to information that might disconfirm one's beliefs.
The result of confirmation bias is that people are unlikely to change their minds about something that they have a pre-existing belief about, because they tend to look only for information that supports their pre-existing beliefs.
For instance, if you believe that a particular player is a strong breakout candidate to be a sleeper, you may be more likely to pay attention to evidence that supports that the player will breakout and may be less likely to pay attention to evidence that indicates the player may struggle.

As a budding empiricist, you should actively seek out information that challenges or disconfirms your beliefs and work to incorporate it into your beliefs.
Do your best to go into observation, data analysis, and data interpretation with an open mind.

### Recency Bias {#sec-cognitiveBiasesRecency}

*Recency bias* is the tendency to weigh recent events more than earlier ones.
For instance, a manager might observe that a Running Back on the waiver wire performed well in the last two games.
*Recency bias* may lead the manager to pick up the player, overvaluing their recent performance.
For instance, the manager may not have adequately weighed the player's overall season performance and the fact that the starting Running Back is returning to the lineup from injury, and that is why the player received more carries in the past two games (i.e., in place of the injured starter).

### Hindsight Bias {#sec-cognitiveBiasesHindsight}

> "Hindsight is 20/20." – Idiom

*Hindsight bias* is the tendency to perceive that past events were more predictable than they were.
People tend to remember the succeess of their predictions and forget the failures of their predictions.
For instance, if a third-string Quarterback has a breakout game, a fantasy manager may claim that they "knew it all along" that the player was going to breakout, despite not having picked up the player.
That same manager may forget the many other predictions they had that did not come true.

### Loss Aversion Bias {#sec-cognitiveBiasesLossAversion}

*Loss aversion bias* is the tendency to avoid losses rather than acquiring equivalent gains.
Loss aversion is exemplified when teams play conservatively so as "not to lose" instead of "to win."
In fantasy football, loss aversion may lead managers to start or hold onto underperforming high drafts for too long instead of a starting a more promising player out of fear of losing potential value from their initial investment.

### Endowment Bias {#sec-cognitiveBiasesEndowment}

*Endowment bias* is the tendency to overvalue merely because one owns it.
For instance, a manager might overvalue a player they drafted in the first round, refusing to trade them even if they could get a better-performing player in return.

### Bandwagon Effect Bias {#sec-cognitiveBiasesBandwagon}

The *bandwagon effect bias* is the tendency to do or believe things because other people are.
It involves social conformity.
For instance, consider if a rookie Wide Receiver has a breakout game and he is picked up in many fantasy leagues.
A given manager might pick up the player because the player is frequently being picked up in many fantasy leagues, without evaluating whether the player's success is sustainable.

### Dunning–Kruger Effect Bias {#sec-cognitiveBiasesDunningKruger}

> "The more you know, the more you know you don't know." – Anonymous

The *Dunning–Kruger effect bias* is the tendency for people with low ability/competency in a task to overestimate their ability.
The Dunning–Kruger effect is depicted in Figures [-@fig-dunningKrueger1] and [-@fig-dunningKrueger2].
For instance, consider a new fantasy manager who experiences some initial wins (often called "beginner's luck").
They may attribute their successes to their skill rather than to luck.
Their [overconfidence](#sec-cognitiveBiasesOverconfidence) may lead them to believe they can win the league without much preparation.

::: {#fig-dunningKrueger1}
![](images/dunningKrueger_1.png)

Dunning–Krueger Effect: Confidence as a Function of Competence. Adapted from <https://commons.wikimedia.org/wiki/File:Effet_Dunning-Kruger.svg>.
:::

::: {#fig-dunningKrueger2}
![](images/dunningKrueger_2.png)

Dunning–Krueger Effect: Perceived Performance as a Function of Actual Performance. Adapted from <https://commons.wikimedia.org/wiki/File:Dunning-kruger_effect_-_percentile.svg>.
:::

## Examples of Fallacies {#sec-fallacies}

As described [above](#sec-cognitiveBiasOverview), fallacies are mistaken beliefs and flawed reasoning.
Fallacies are often due to the use of [heuristics](#sec-heuristics) and to [cognitive biases](#sec-cognitiveBiases).
Examples of fallacies include:

- base rate fallacy (aka base rate neglect)
- regression fallacy
- sunk cost fallacy
- hot hand fallacy
- gambler's fallacy
- conditional probability fallacy

### Base Rate Fallacy {#sec-fallaciesBaseRate}

The *base rate fallacy* (aka base rate neglect) is the tendency to ignore information about the general probability of an event in favor of specific information about the event.
The *base rate* is a marginal probability, which is the general probability of an event irrespective of other things.
For example, the base rate of work-related injury is the general probability of experiencing a work-related injury, irrespective of other factors (e.g., the type of job, the person's age, the person's sex).
Among the working population in the U.S., the lifetime prevalence of work-related injuries (i.e., the percent of people who will experience a work-related injury at some point in their lives), is ~35% (<https://www.cdc.gov/mmwr/volumes/69/wr/mm6913a1.htm>; archived at <https://perma.cc/A2L6-WPEH>).
Thus, the base rate of work-related injuries in the U.S. is ~35%.
The probability of work-related injuries is higher for some occupations (e.g., construction) and for some groups (e.g., men, 55–64-year-olds, Black or Multiracial, who are self-employed and have less than high school education) than others.
Nevertheless, if we ignore all of the interacting factors, the general probability of work-related injuries is 35%.
If we made a prediction that someone would be highly likely (> 90%) to experience a work-related injury because they are male and self-employed, this would be ignoring the relatively lower base rate of work-related injury.
Indeed, even men (36.7%) and self-employed individuals (41.2%) have less than a 50% chance of experiencing a work-related injury.

As applied to fantasy football, consider that you read about a potential sleeper Wide Receiver who had a stellar performance in a preseason game.
If you select this player early on in the draft based on this information, this would be ignoring the general probability that most players who have a strong performance in the preseason do not perform as well in the regular season (i.e., base rate neglect).
Performance in the preseason is not strongly predictive of performance in the regular season (<https://fivethirtyeight.com/features/the-nfl-preseason-is-not-predictive-but-it-can-often-seem-that-way/>; archived at <https://perma.cc/FSG2-6AXE>).

More information on base rates and how to counteract the base rate fallacy in described in @sec-baseRates.

### Regression Fallacy {#sec-fallaciesRegression}

The regression fallacy is the failure to account for the fact that things tend to naturally fluctuate around their mean and that, after an extreme fluctuation, subsequent scores tend to regress (or reverse) to the mean.
An example of the regression fallacy is the so-called Sports Illustrated or Madden cover jinx curse.
The Sports Illustrated or Madden cover jinx curse is the urban legend that players who appear on the cover of Sports Illustrated (the magazine) or Madden (the video game) will perform poorly.
But, such a phenomenon can be more simply explained by regression to the mean (<https://www.psychologytoday.com/us/blog/what-the-luck/201610/the-sports-illustrated-cover-jinx>; archived at <https://perma.cc/CZM9-TVFN>).
When a player has a superb season, they likely benefited from some degree to good luck, and it is unlikely that they will repeat such a stellar season the following year.
Instead, they are likely—at least based on random fluctuation—to regress to their long-term mean.

Applied to fantasy football, consider that a Quarterback had a 5-touchdown game in Week 1.
You are in need of a strong Quarterback, so you drop a solid player to pick him up.
However, it is possible that the Quarterback benefited from playing against a week defense in the first game of the season.
Future matchups may prove more difficult, and the player is unlikely to sustain such a solid performance consistently throughout the season (i.e., they are likely to regress toward their mean).

### Hot Hand Fallacy {#sec-fallaciesHotHand}

The "hot hand" is the idea that a player who experiences a successful outcome will have greater chance of success in subsequent attempts.
For instance, in basketball, it is widely claimed by coaches, players, and commentators that players who have the hot hand (i.e., who are "on fire") are more likely to make shots because they made previous shots.
Evidence on the hot hand is mixed.
Considerable evidence historically has suggested that there is no such thing as a "hot hand" [@Gilovich1985; @BarEli2006; @Avugos2013].
Some recent research, however, has suggested that there may be a small hot hand effect in some contexts [@Bocskocsky2014; @Miller2014a].
However, if any such effect exists, the hot hand may be limited to a small subset of players and the [effect size](#sec-practicalSignificance) of any hot hand effect appears to be small [@Pelechrinis2022].

In football, when trying how to distribute the ball among multiple Running Backs, it is not uncommon to hear that a coach wants to give the ball to the Running Back with the "hot hand."
In fantasy football, consider that a player just had a multiple touchdown game.
Due to the hot hand fallacy, a manager might continue to start the player because they believe the player is "on fire" and is likely to continue to score at an unsustainable rate.

It is important consider whether such a string of strong performances are outliers and if the player may, in future games, [regress to the mean](#sec-fallaciesRegression).
When considering whether strong performances are outliers and may [regress to the mean](#sec-fallaciesRegression), it is valuable to consider whether the player's health, skill, or situation has appreciably changed (compared to the player's earlier, weaker performances).
Is the player finally fully healthy?
Has the player appreciably improved in some skill that will benefit them in future games?
Has the player's long-term situation improved, such as moving up the depth chart, or receiving more carries/targets that is not tied to a specific opponent or game script?
Or, alternatively, do the improvements appear to be driven by transient, game-specific factors, such as a the health of a teammate, the opponents they played, or the game script that ensued?
If long-term outlook of the player has appreciably changed due to changes in the [fundamentals of a player's value](#sec-playerEvaluation), such as their [health](#sec-evalHealth), [skill](#sec-skill), or [situation](#sec-evalSituation), it is less likely that such performance improvements will [regress](#sec-fallaciesRegression) over the long run.

### Sunk Cost Fallacy {#sec-fallaciesSunkCost}

A *sunk cost* is a cost (e.g., in money, time, or effort) that has already been incurred and cannot be recovered.
For instance, if a person orders an expensive meal at a restaurant, the order is a sunk cost.
The *sunk cost fallacy* is the tendency to continue an endeavor when there is a sunk cost.
For instance, when ordering the expensive meal at the restaurant, a person may over-eat so that they feel that they eat their money's worth of food.

Applied to fantasy football, consider a situation in which you invest a lot of salary cap or a high draft pick to draft a promising player, but they repeatedly underperform.
If you continue to start the player to justify your large investment, instead of benching him in favor of a higher-performing player, you are committing the sunk cost fallacy.

### Gambler's Fallacy {#sec-fallaciesGambler}

The gambler's fallacy occurs due to an erroneous belief in the law of small numbers.
The law of large numbers is a mathematical theorem that the average of a sufficiently large number of independent observations converges to the true value.
For instance, if you flip a fair coin 1 million times, it is likely to land heads-up ~50% of the time.
The law of *small* numbers (aka hasty generalization), by contrast, is an erroneous belief that small samples are representative of the populations from which they were drawn.
For instance, if you flip a coin 10 times, belief in the law of small numbers would lead one to believe that the coin will flip heads-up exactly 5 times out of 10.
However, in reality, the chance is less than 1 in 4 (24.6%) that exactly 5 of 10 coin flips turn up heads, as calculated below and as depicted in @fig-simulationOf10CoinFlips:

```{r}
dbinom(
  x = 5,     # number of coins that flip heads-up
  size = 10, # how many times you flip a coin
  prob = 0.5 # probability of a coin flipping heads-up (i.e., fair coin = 50%)
)
```

The `dbinom()` function in R provides the density of a binomial distribution.
A binomial distribution is the probability of a particular number of successes (e.g., coins flipping heads-up) given a certain number of independent trials.

```{r}
#| fig-cap: "Histogram of Number of Coins that Flip Heads-Up in a Simulation of 10 Coin Flips (with 100,000 Replications)."
#| label: fig-simulationOf10CoinFlips
#| code-fold: true

set.seed(52242)

numHeads <- rbinom(
  n = 100000,
  size = 10,
  prob = .5
)

simulationOfFlipping10Coins <- data.frame(
  numHeads = numHeads
)

simulationOfFlipping10Coins <- simulationOfFlipping10Coins %>% 
  mutate(
    highlight = ifelse(numHeads == 5, "yes", "no")
  )

ggplot2::ggplot(
  data = simulationOfFlipping10Coins,
  mapping = aes(
    x = numHeads,
    fill = highlight)
) +
  geom_histogram(
    color = "#000000",
    bins = 11
  ) +
  scale_x_continuous(
    breaks = 0:10
  ) +
  scale_fill_manual(
    values = c(
      "yes" = "tomato",
      "no" = "gray")
  ) +
  labs(
    x = "Number of Coins Flipped Heads (out of 10 Coin Flips)",
    y = "Frequency",
    title = "Histogram of Number of Coins that Flip Heads-Up\nin a Simulation of 10 Coin Flips\n(with 100,000 Replications)."
  ) +
  theme_classic() +
  theme(legend.position = "none")
```

Although 5 is the modal count of coins that flip heads-up out of 10 flips (i.e., it was more common than any other number), it is less common than the aggregate probability of flipping any number of heads besides 5.
The probability of getting any other number of coin flips turning up heads (other than 5) is:

```{r}
dbinom(
  x = c(0:4, 6:10),
  size = 10,
  prob = 0.5
) %>% sum()
```

The *gambler's fallacy* is the erroneous belief that future probabilities are influenced by past events, even when the events are independent.
For example, a gambler may pay close attention to a particular slot machine.
If the slot machine has not paid out in a while, the gambler may believe that the slot machine is about to pay out soon, and may start putting coins in the slots.

Applied to fantasy football, consider that a Quarterback has had several lousy games in a row.
The gambler's fallacy might lead a manager to start the player under the belief that the player "is due" for a big game, expecting a strong performance from the player merely because they player has not had a good game in a while.

### Conditional Probability Fallacy {#sec-fallaciesConditionalProbability}

We describe the [conditional probability fallacy](#sec-inverseFallacy) in @sec-inverseFallacy after introducing [conditional probability](#sec-conditionalProbability) in @sec-conditionalProbability.

## Conclusion {#sec-cognitiveBiasConclusion}

In conclusion, there are many [heuristics](#sec-heuristics), [cognitive bias](#sec-cognitiveBiases), and [fallacies](#sec-fallacies) that people engage in when making judgments and predictions.
It is prudent to be aware of these common biases and to work to counteract them.
For instance, look for information that challenges or disconfirms your beliefs, and work to incorporate this information into your beliefs.
Do your best to pursue observation, data analysis, and data interpretation with an open mind.
You never know what important information you might discover if you go in with an open mind.
Pay attention to [fundamentals of a player's value](#sec-playerEvaluation), such as their [health](#sec-evalHealth), [skill](#sec-skill), or [situation](#sec-evalSituation) when considering whether a player's performance may [regress to the mean](#sec-fallaciesRegression).
If the strong performances appear to be driven by transient, game-specific factors, such as a the health of a teammate, the opponents they played, or the game script that ensued, future performances may be more likely to [regress to the mean](#sec-fallaciesRegression).
In general, people tend to be [overconfident](#sec-cognitiveBiasesOverconfidence) in their predictions.
There is considerable luck in fantasy football.
Approach the task of prediction with humility; no one is consistently able to accurately predict how well players will perform.

::: {.content-visible when-format="html"}

## Session Info {#sec-cognitiveBiasSessionInfo}

```{r}
sessionInfo()
```

:::
