# Heuristics and Cognitive Biases in Prediction {#sec-cognitiveBias}

## Getting Started {#sec-cognitiveBiasGettingStarted}

### Load Packages {#sec-cognitiveBiasLoadPackages}

```{r}

```

## Overview {#sec-cognitiveBiasOverview}

When considering judgment and prediction, it is important to consider psychological concepts, including heuristics and cognitive biases.
In the modern world of big data, research and society need people who know how to make sense of the information around us.
Given humans' cognitive biases, it is valuable to leverage more objective approaches than relying on our "gut" and intutition.
Statistical approaches can be a more objective way to identify systematic patterns.

Statistical analysis—and science more generally—is a process to the pursuit of knowledge.
An *epistemology* is an approach to knowledge.
Science is perhaps the best approach (epistemology) that society has to approximate truth.
Unlike other approaches to knowledge, science relies on empirical evidence and does not give undue weight to anecdotal evidence, intuition, tradition, or authority.

Per @PetersenPrinciplesPsychAssessment, here are the characteristics of science that distinguish it from pseudoscience:

> 1. Risky hypotheses are posed that are falsifiable.
> The hypotheses can be shown to be wrong.
> 1. Findings can be replicated independently by different research groups and different methods.
> Evidence converges across studies and methods.
> 1. Potential alternative explanations for findings are specified and examined empirically (with data).
> 1. Steps are taken to guard against the undue influence of personal beliefs and biases.
> 1. The strength of claims reflects the strength of evidence.
> Findings and the ability to make judgments or predictions are not overstated.
> For instance, it is important to present the degree of uncertainty from assessments with error bars or confidence intervals.
> 1. Scientifically supported measurement strategies are used based on their psychometrics, including [reliability](#sec-reliability) and [validity](#sec-validity).

Nevertheless, statistical analysis is not purely objective and is not a panacea.
Science is a human enterprise—it is performed by humans each of whom has their own biases.
For instance, cognitive biases can influence how people interpret statistics.
As a result, the findings from any given study may be incorrect.
Thus, it would be imprudent to make decisions based solely on the results of one study.
That is why we wait for findings to be independently replicated by different groups of researchers using different methods.

If a research team publishes flashy new and exciting findings, other researchers have an incentive to disprove the prior findings.
Thus, we have more confidence if findings stand up to scrutiny from independent groups of researchers.
We also draw upon meta-analyses—studies of many studies, to summarize the results of many studies and not just the findings from any single study that may not replicate.
In this way, we can identify which findings are robust and most likely true versus the findings that fail to replicate.
Thus, despite its flaws like any other human enterprise, science is a self-correcting process in which the long arc bends toward truth.

In our everyday lives, humans are presented with overwhelming amounts of information.
Because human minds cannot parse every piece of information equally, we tend to take mental shortcuts, called *heuristics*.
These mental shortcuts can be helpful.
They reduce our mental load and can help us make quick judgments to stay alive or to make complex decisions in the face of uncertainty.
However, these mental shortcuts can also lead us astray and make systematic errors in our judgments and predictions.
*Cognitive biases* are systematic errors in thinking.

## Examples of Heuristics {#sec-heuristics}

Three important heuristics used in judgment and prediction in the face of uncertainty include [@Tversky1974]:

- availability
- representativeness
- anchoring and adjustment

The *availability heuristic* refers to the tendency for a person's judgments or predictions about the frequency or probability of something to be made based on how readily instances can be brought to mind.
For instance, when making fantasy predictions about a player, more recent big performance games may more easily come to mind compared to lower-scoring games and games that occurred longer ago.
Thus, a manager may be more inclined to pick players to start who had more recent, stronger performances rather than players who have higher long-term averages.

The *representativess heuristic* refers to the tendency for a person's judgments or predictions about individuals to be made based on how similar the individual is to the person's existing mental prototypes.
For instance, when coming out of college, Tight End Kyle Pitts [drew comparisons](https://247sports.com/article/kyle-pitts-lebron-james-2021-nfl-draft-florida-gators-football-163882176) to the "LeBron James" of Tight Ends (archived at <https://perma.cc/JQB5-XPVL>).
The idea that his athletic profile leads him to be similar to the prototype of LeBron James may have led him to be too highly drafted by fantasy managers in his first seasons.

::: {.content-visible when-format="html:js"}

Here is a video of Kyle Pitts drawing comparisons to the LeBron James of Tight Ends:

![Video of Kyle Pitts drawing comparisons to the LeBron James of Tight Ends. From: <https://x.com/GetUpESPN/status/1380165126108672001> (archived at <https://perma.cc/JW8E-KV2C>)](images/kylePitts.mp4){width=100%}

:::

The representativeness heuristic has been observed in gambling markets for predicting team wins in the National Football League (NFL) [@Woodland2015] and in decision making in fantasy soccer [@Kotrba2020].

The *anchoring and adjustment heuristic* refers to the tendency for a person's judgments or predictions to be made with a reference point—an anchor—as a starting point from which they adjust their estimates upward or downward.
The anchor is often inaccurate and given too much weight in the person's calculation, and too little adjustment is made to the anchor.
For instance, a manager is trying to predict how many fantasy points a top Running Back may score.
The player scored 300 fantasy points last season, but the team added a stronger backup Running Back and changed the Offensive Coordinator to be a more pass-heavy offense.
The manager may use 300 fantasy points as an anchor (based on the player's performance last season), and may adjust downward 15 points to account for the offseason changes.
However, it is possible that this downward adjustment is insufficient to account not only for the offseasons changes but also for potential regression effects.
Regression effects are discussed further below.

## Examples of Cognitive Biases {#sec-cognitiveBiases}

Examples of cognitive biases that result from one or more of these heuristics include:

- base rate neglect
- forgetting about regression to the mean
- overconfidence
- confirmation bias
- hindsight bias
- loss aversion bias
- endowment bias
- Dunning–Kruger effect

## Examples of Fallacies {#sec-fallacies}

Fallacies are mistaken beliefs that are often due to heuristics and cognitive biases.
Examples of fallacies include:

- sunk cost fallacy
- hot hand fallacy
- gambler's fallacy

## Conclusion {#sec-cognitiveBiasConclusion}

::: {.content-visible when-format="html"}

## Session Info {#sec-cognitiveBiasSessionInfo}

```{r}
sessionInfo()
```

:::
